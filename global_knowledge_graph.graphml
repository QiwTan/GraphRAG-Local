<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d2" for="edge" attr.name="weight" attr.type="double" />
  <key id="d1" for="edge" attr.name="relation" attr.type="string" />
  <key id="d0" for="node" attr.name="label" attr.type="string" />
  <graph edgedefault="directed">
    <node id="Parker Barnes">
      <data key="d0">Parker Barnes</data>
    </node>
    <node id="Emily Reif">
      <data key="d0">Emily Reif</data>
    </node>
    <node id="Kensen Shi">
      <data key="d0">Kensen Shi</data>
    </node>
    <node id="Paul Barham">
      <data key="d0">Paul Barham</data>
    </node>
    <node id="Jacob Devlin">
      <data key="d0">Jacob Devlin</data>
    </node>
    <node id="Aakanksha Chowdhery">
      <data key="d0">Aakanksha Chowdhery</data>
    </node>
    <node id="Vinodkumar Prabhakaran">
      <data key="d0">Vinodkumar Prabhakaran</data>
    </node>
    <node id="PaLM: Scaling Language Modeling with Pathways">
      <data key="d0">PaLM: Scaling Language Modeling with Pathways</data>
    </node>
    <node id="Hyung Won Chung">
      <data key="d0">Hyung Won Chung</data>
    </node>
    <node id="Jude Jenkins">
      <data key="d0">Jude Jenkins</data>
    </node>
    <node id="Nan Du">
      <data key="d0">Nan Du</data>
    </node>
    <node id="Sasha Tsvyashchenko">
      <data key="d0">Sasha Tsvyashchenko</data>
    </node>
    <node id="Charles Sutton">
      <data key="d0">Charles Sutton</data>
    </node>
    <node id="Maarten Bosma">
      <data key="d0">Maarten Bosma</data>
    </node>
    <node id="Abhishek Rao">
      <data key="d0">Abhishek Rao</data>
    </node>
    <node id="Language Modeling">
      <data key="d0">Language Modeling</data>
    </node>
    <node id="Adam Roberts">
      <data key="d0">Adam Roberts</data>
    </node>
    <node id="Reiner Pope">
      <data key="d0">Reiner Pope</data>
    </node>
    <node id="Parker Schuh">
      <data key="d0">Parker Schuh</data>
    </node>
    <node id="Sharan Narang">
      <data key="d0">Sharan Narang</data>
    </node>
    <node id="PaLM">
      <data key="d0">PaLM</data>
    </node>
    <node id="Ben Hutchinson">
      <data key="d0">Ben Hutchinson</data>
    </node>
    <node id="Joshua Maynez">
      <data key="d0">Joshua Maynez</data>
    </node>
    <node id="Noam Shazeer">
      <data key="d0">Noam Shazeer</data>
    </node>
    <node id="Yi Tay">
      <data key="d0">Yi Tay</data>
    </node>
    <node id="Gaurav Mishra">
      <data key="d0">Gaurav Mishra</data>
    </node>
    <node id="James Bradbury">
      <data key="d0">James Bradbury</data>
    </node>
    <node id="Sebastian Gehrmann">
      <data key="d0">Sebastian Gehrmann</data>
    </node>
    <node id="Xuezhi Wang">
      <data key="d0">Xuezhi Wang</data>
    </node>
    <node id="Oleksandr Polozov">
      <data key="d0">Oleksandr Polozov</data>
    </node>
    <node id="Zongwei Zhou">
      <data key="d0">Zongwei Zhou</data>
    </node>
    <node id="Jason Wei">
      <data key="d0">Jason Wei</data>
    </node>
    <node id="Rewon Child">
      <data key="d0">Rewon Child</data>
    </node>
    <node id="Jeﬀ Dean">
      <data key="d0">Jeﬀ Dean</data>
    </node>
    <node id="Noah Fiedel">
      <data key="d0">Noah Fiedel</data>
    </node>
    <node id="Katherine Lee">
      <data key="d0">Katherine Lee</data>
    </node>
    <node id="Mark Diaz">
      <data key="d0">Mark Diaz</data>
    </node>
    <node id="Orhan Firat">
      <data key="d0">Orhan Firat</data>
    </node>
    <node id="Erica Moreira">
      <data key="d0">Erica Moreira</data>
    </node>
    <node id="Brennan Saeta">
      <data key="d0">Brennan Saeta</data>
    </node>
    <node id="Michele Catasta">
      <data key="d0">Michele Catasta</data>
    </node>
    <node id="model scale">
      <data key="d0">model scale</data>
    </node>
    <node id="bias and toxicity">
      <data key="d0">bias and toxicity</data>
    </node>
    <node id="BIG-bench benchmark">
      <data key="d0">BIG-bench benchmark</data>
    </node>
    <node id="google.com">
      <data key="d0">google.com</data>
    </node>
    <node id="hundreds of language understanding and generation benchmarks">
      <data key="d0">hundreds of language understanding and generation benchmarks</data>
    </node>
    <node id="multi-step reasoning tasks">
      <data key="d0">multi-step reasoning tasks</data>
    </node>
    <node id="wide array of benchmarks">
      <data key="d0">wide array of benchmarks</data>
    </node>
    <node id="multilingual tasks and source code generation">
      <data key="d0">multilingual tasks and source code generation</data>
    </node>
    <node id="Chowdhery">
      <data key="d0">Chowdhery</data>
    </node>
    <node id="chowdhery@google.com">
      <data key="d0">chowdhery@google.com</data>
    </node>
    <node id="Moonshot Factory">
      <data key="d0">Moonshot Factory</data>
    </node>
    <node id="researcher at Google">
      <data key="d0">researcher at Google</data>
    </node>
    <node id="sharannarang@google.com">
      <data key="d0">sharannarang@google.com</data>
    </node>
    <node id="Alphabet">
      <data key="d0">Alphabet</data>
    </node>
    <node id="Google">
      <data key="d0">Google</data>
    </node>
    <node id="training dataset">
      <data key="d0">training dataset</data>
    </node>
    <node id="Code Tasks">
      <data key="d0">Code Tasks</data>
    </node>
    <node id="Training Infrastructure">
      <data key="d0">Training Infrastructure</data>
    </node>
    <node id="Efficiency">
      <data key="d0">Efficiency</data>
    </node>
    <node id="Translation">
      <data key="d0">Translation</data>
    </node>
    <node id="Analysis">
      <data key="d0">Analysis</data>
    </node>
    <node id="Multilingual Question Answering">
      <data key="d0">Multilingual Question Answering</data>
    </node>
    <node id="English NLP tasks">
      <data key="d0">English NLP tasks</data>
    </node>
    <node id="Evaluation">
      <data key="d0">Evaluation</data>
    </node>
    <node id="Training Setup">
      <data key="d0">Training Setup</data>
    </node>
    <node id="6">
      <data key="d0">6</data>
    </node>
    <node id="Reasoning">
      <data key="d0">Reasoning</data>
    </node>
    <node id="BIG-bench">
      <data key="d0">BIG-bench</data>
    </node>
    <node id="Training Dataset">
      <data key="d0">Training Dataset</data>
    </node>
    <node id="Multilingual Natural Language Generation">
      <data key="d0">Multilingual Natural Language Generation</data>
    </node>
    <node id="Instability">
      <data key="d0">Instability</data>
    </node>
    <node id="Ethical Considerations">
      <data key="d0">Ethical Considerations</data>
    </node>
    <node id="Conclusion">
      <data key="d0">Conclusion</data>
    </node>
    <node id="Open Questions in Scaling">
      <data key="d0">Open Questions in Scaling</data>
    </node>
    <node id="Toxicity in open-ended generation">
      <data key="d0">Toxicity in open-ended generation</data>
    </node>
    <node id="Related Work">
      <data key="d0">Related Work</data>
    </node>
    <node id="Dataset Contamination">
      <data key="d0">Dataset Contamination</data>
    </node>
    <node id="Limitations">
      <data key="d0">Limitations</data>
    </node>
    <node id="Representational Bias Analysis">
      <data key="d0">Representational Bias Analysis</data>
    </node>
    <node id="Memorization">
      <data key="d0">Memorization</data>
    </node>
    <node id="BERT and T5">
      <data key="d0">BERT and T5</data>
    </node>
    <node id="Bert (Devlin et al., 2019)">
      <data key="d0">Bert (Devlin et al., 2019)</data>
    </node>
    <node id="Authors (Raffel et al.)">
      <data key="d0">Authors (Raffel et al.)</data>
    </node>
    <node id="T5 (Raffel et al., 2020)">
      <data key="d0">T5 (Raffel et al., 2020)</data>
    </node>
    <node id="BIG-bench results">
      <data key="d0">BIG-bench results</data>
    </node>
    <node id="English NLP tasks on smaller models">
      <data key="d0">English NLP tasks on smaller models</data>
    </node>
    <node id="Authors (Devlin et al.)">
      <data key="d0">Authors (Devlin et al.)</data>
    </node>
    <node id="masked LM">
      <data key="d0">masked LM</data>
    </node>
    <node id="natural language tasks">
      <data key="d0">natural language tasks</data>
    </node>
    <node id="GPT-3">
      <data key="d0">GPT-3</data>
    </node>
    <node id="T5">
      <data key="d0">T5</data>
    </node>
    <node id="BERT">
      <data key="d0">BERT</data>
    </node>
    <node id="Few-shot evaluation">
      <data key="d0">Few-shot evaluation</data>
    </node>
    <node id="Megatron–Turing NLG">
      <data key="d0">Megatron–Turing NLG</data>
    </node>
    <node id="GLaM">
      <data key="d0">GLaM</data>
    </node>
    <node id="Chinchilla">
      <data key="d0">Chinchilla</data>
    </node>
    <node id="Gopher">
      <data key="d0">Gopher</data>
    </node>
    <node id="few-shot predictions">
      <data key="d0">few-shot predictions</data>
    </node>
    <node id="LaMDA">
      <data key="d0">LaMDA</data>
    </node>
    <node id="natural language task description">
      <data key="d0">natural language task description</data>
    </node>
    <node id="decoder-only architecture">
      <data key="d0">decoder-only architecture</data>
    </node>
    <node id="Transformer architecture">
      <data key="d0">Transformer architecture</data>
    </node>
    <node id="780 billion tokens of high-quality text">
      <data key="d0">780 billion tokens of high-quality text</data>
    </node>
    <node id="Pathways">
      <data key="d0">Pathways</data>
    </node>
    <node id="state-of-the-art few-shot results">
      <data key="d0">state-of-the-art few-shot results</data>
    </node>
    <node id="breakthrough performance">
      <data key="d0">breakthrough performance</data>
    </node>
    <node id="540 billion">
      <data key="d0">540 billion</data>
    </node>
    <node id="780 billion tokens of text">
      <data key="d0">780 billion tokens of text</data>
    </node>
    <node id="thousands of accelerator chips">
      <data key="d0">thousands of accelerator chips</data>
    </node>
    <node id="hundreds of natural language tasks">
      <data key="d0">hundreds of natural language tasks</data>
    </node>
    <node id="very large neural networks">
      <data key="d0">very large neural networks</data>
    </node>
    <node id="hundreds of natural language, code, and mathematical reasoning tasks">
      <data key="d0">hundreds of natural language, code, and mathematical reasoning tasks</data>
    </node>
    <node id="Barham et al.">
      <data key="d0">Barham et al.</data>
    </node>
    <node id="TPU v4 chips">
      <data key="d0">TPU v4 chips</data>
    </node>
    <node id="whale">
      <data key="d0">whale</data>
    </node>
    <node id="Section 6">
      <data key="d0">Section 6</data>
    </node>
    <node id="TPU v4 Pods">
      <data key="d0">TPU v4 Pods</data>
    </node>
    <node id="Chinese language">
      <data key="d0">Chinese language</data>
    </node>
    <node id="46.2%">
      <data key="d0">46.2%</data>
    </node>
    <node id="TPU team">
      <data key="d0">TPU team</data>
    </node>
    <node id="Zeng et al.">
      <data key="d0">Zeng et al.</data>
    </node>
    <node id="Seattle, Washington">
      <data key="d0">Seattle, Washington</data>
    </node>
    <node id="Virginia">
      <data key="d0">Virginia</data>
    </node>
    <node id="Shelley">
      <data key="d0">Shelley</data>
    </node>
    <node id="Pacific Ocean">
      <data key="d0">Pacific Ocean</data>
    </node>
    <node id="new few-shot state of the art on 28 out of the 29 most widely evaluated English language understanding benchmarks">
      <data key="d0">new few-shot state of the art on 28 out of the 29 most widely evaluated English language understanding benchmarks</data>
    </node>
    <node id="2-shot exemplars">
      <data key="d0">2-shot exemplars</data>
    </node>
    <node id="Table 4">
      <data key="d0">Table 4</data>
    </node>
    <node id="PaLM 540B">
      <data key="d0">PaLM 540B</data>
    </node>
    <node id="GLaM, GPT-3, Megatron–Turing NLG, Gopher, Chinchilla, LaMDA">
      <data key="d0">GLaM, GPT-3, Megatron–Turing NLG, Gopher, Chinchilla, LaMDA</data>
    </node>
    <node id="explanations using chain-of-thought prompting (Wei et al., 2022b)">
      <data key="d0">explanations using chain-of-thought prompting (Wei et al., 2022b)</data>
    </node>
    <node id="large LMs">
      <data key="d0">large LMs</data>
    </node>
    <node id="Seattle">
      <data key="d0">Seattle</data>
    </node>
    <node id="Section 9">
      <data key="d0">Section 9</data>
    </node>
    <node id="Section 6.3">
      <data key="d0">Section 6.3</data>
    </node>
    <node id="62B">
      <data key="d0">62B</data>
    </node>
    <node id="Kaplan et al.">
      <data key="d0">Kaplan et al.</data>
    </node>
    <node id="8B">
      <data key="d0">8B</data>
    </node>
    <node id="power law rule of thumb">
      <data key="d0">power law rule of thumb</data>
    </node>
    <node id="540B">
      <data key="d0">540B</data>
    </node>
    <node id="state of the art">
      <data key="d0">state of the art</data>
    </node>
    <node id="BIG-bench collaboration">
      <data key="d0">BIG-bench collaboration</data>
    </node>
    <node id="exploratory capabilities">
      <data key="d0">exploratory capabilities</data>
    </node>
    <node id="few-shot evaluation">
      <data key="d0">few-shot evaluation</data>
    </node>
    <node id="discontinuous improvements">
      <data key="d0">discontinuous improvements</data>
    </node>
    <node id="150+ new language understanding and generation tasks">
      <data key="d0">150+ new language understanding and generation tasks</data>
    </node>
    <node id="Section 6.7">
      <data key="d0">Section 6.7</data>
    </node>
    <node id="summarization">
      <data key="d0">summarization</data>
    </node>
    <node id="question answering">
      <data key="d0">question answering</data>
    </node>
    <node id="Section 6.6">
      <data key="d0">Section 6.6</data>
    </node>
    <node id="machine translation">
      <data key="d0">machine translation</data>
    </node>
    <node id="Section 6.2">
      <data key="d0">Section 6.2</data>
    </node>
    <node id="Section 6.5">
      <data key="d0">Section 6.5</data>
    </node>
    <node id="prior state of the art in translation tasks">
      <data key="d0">prior state of the art in translation tasks</data>
    </node>
    <node id="gender and occupation bias on the Winogender coreference task">
      <data key="d0">gender and occupation bias on the Winogender coreference task</data>
    </node>
    <node id="Muslims">
      <data key="d0">Muslims</data>
    </node>
    <node id="1-shot and few-shot settings">
      <data key="d0">1-shot and few-shot settings</data>
    </node>
    <node id="terrorism, extremism, and violence">
      <data key="d0">terrorism, extremism, and violence</data>
    </node>
    <node id="prior state of the art in non-English summarization tasks">
      <data key="d0">prior state of the art in non-English summarization tasks</data>
    </node>
    <node id="Winogender coreference task">
      <data key="d0">Winogender coreference task</data>
    </node>
    <node id="PaLM 8B">
      <data key="d0">PaLM 8B</data>
    </node>
    <node id="PaLM 62B">
      <data key="d0">PaLM 62B</data>
    </node>
    <node id="overall toxicity level">
      <data key="d0">overall toxicity level</data>
    </node>
    <node id="Transformer">
      <data key="d0">Transformer</data>
    </node>
    <node id="Vaswani et al.">
      <data key="d0">Vaswani et al.</data>
    </node>
    <node id="standard ReLU variant">
      <data key="d0">standard ReLU variant</data>
    </node>
    <node id="SwiGLU Activation">
      <data key="d0">SwiGLU Activation</data>
    </node>
    <node id="Parallel Layers">
      <data key="d0">Parallel Layers</data>
    </node>
    <node id="Transformer model architecture">
      <data key="d0">Transformer model architecture</data>
    </node>
    <node id="Ablation experiments">
      <data key="d0">Ablation experiments</data>
    </node>
    <node id="training speed">
      <data key="d0">training speed</data>
    </node>
    <node id="Transformer formulation">
      <data key="d0">Transformer formulation</data>
    </node>
    <node id="8B scale">
      <data key="d0">8B scale</data>
    </node>
    <node id="62B scale">
      <data key="d0">62B scale</data>
    </node>
    <node id="Multi-Query Attention">
      <data key="d0">Multi-Query Attention</data>
    </node>
    <node id="quality neutral effect of parallel layers">
      <data key="d0">quality neutral effect of parallel layers</data>
    </node>
    <node id="15% faster training speed">
      <data key="d0">15% faster training speed</data>
    </node>
    <node id="Biases">
      <data key="d0">Biases</data>
    </node>
    <node id="RoPE Embeddings">
      <data key="d0">RoPE Embeddings</data>
    </node>
    <node id="SentencePiece">
      <data key="d0">SentencePiece</data>
    </node>
    <node id="Absolute Position Embeddings">
      <data key="d0">Absolute Position Embeddings</data>
    </node>
    <node id="Input-Output Embeddings">
      <data key="d0">Input-Output Embeddings</data>
    </node>
    <node id="UTF-8 bytes">
      <data key="d0">UTF-8 bytes</data>
    </node>
    <node id="8B parameters">
      <data key="d0">8B parameters</data>
    </node>
    <node id="individual digit tokens">
      <data key="d0">individual digit tokens</data>
    </node>
    <node id="PaLM 62B and PaLM 540B">
      <data key="d0">PaLM 62B and PaLM 540B</data>
    </node>
    <node id="64">
      <data key="d0">64</data>
    </node>
    <node id="118">
      <data key="d0">118</data>
    </node>
    <node id="PaLM 8B and PaLM 62B">
      <data key="d0">PaLM 8B and PaLM 62B</data>
    </node>
    <node id="lossless and reversible">
      <data key="d0">lossless and reversible</data>
    </node>
    <node id="32">
      <data key="d0">32</data>
    </node>
    <node id="vocabulary">
      <data key="d0">vocabulary</data>
    </node>
    <node id="numbers">
      <data key="d0">numbers</data>
    </node>
    <node id="whitespace">
      <data key="d0">whitespace</data>
    </node>
    <node id="out-of-vocabulary Unicode characters">
      <data key="d0">out-of-vocabulary Unicode characters</data>
    </node>
    <node id="PaLM 8B and PaLM 540B">
      <data key="d0">PaLM 8B and PaLM 540B</data>
    </node>
    <node id="LaMDA (Thoppilan et al., 2022) and GLaM (Du et al., 2021)">
      <data key="d0">LaMDA (Thoppilan et al., 2022) and GLaM (Du et al., 2021)</data>
    </node>
    <node id="Table 1">
      <data key="d0">Table 1</data>
    </node>
    <node id="Mitchell et al. (2019)">
      <data key="d0">Mitchell et al. (2019)</data>
    </node>
    <node id="16">
      <data key="d0">16</data>
    </node>
    <node id="PaLM pretraining dataset">
      <data key="d0">PaLM pretraining dataset</data>
    </node>
    <node id="PaLM Model Card">
      <data key="d0">PaLM Model Card</data>
    </node>
    <node id="780 billion tokens.">
      <data key="d0">780 billion tokens.</data>
    </node>
    <node id="8">
      <data key="d0">8</data>
    </node>
    <node id="Model architecture details for PaLM models.">
      <data key="d0">Model architecture details for PaLM models.</data>
    </node>
    <node id="model’s architecture, training setup, training data, and intended usage.">
      <data key="d0">model’s architecture, training setup, training data, and intended usage.</data>
    </node>
    <node id="code">
      <data key="d0">code</data>
    </node>
    <node id="webpages">
      <data key="d0">webpages</data>
    </node>
    <node id="GitHub">
      <data key="d0">GitHub</data>
    </node>
    <node id="programming languages">
      <data key="d0">programming languages</data>
    </node>
    <node id="pretraining dataset">
      <data key="d0">pretraining dataset</data>
    </node>
    <node id="source code">
      <data key="d0">source code</data>
    </node>
    <node id="high-quality webpage collections">
      <data key="d0">high-quality webpage collections</data>
    </node>
    <node id="training set">
      <data key="d0">training set</data>
    </node>
    <node id="Java, HTML, Javascript, Python, PHP, C#, XML">
      <data key="d0">Java, HTML, Javascript, Python, PHP, C#, XML</data>
    </node>
    <node id="webpage collections">
      <data key="d0">webpage collections</data>
    </node>
    <node id="source code and social media conversations">
      <data key="d0">source code and social media conversations</data>
    </node>
    <node id="articles">
      <data key="d0">articles</data>
    </node>
    <node id="articles, source code, and social media conversations">
      <data key="d0">articles, source code, and social media conversations</data>
    </node>
    <node id="PaLM dataset mixture creation">
      <data key="d0">PaLM dataset mixture creation</data>
    </node>
    <node id="GitHub (code)">
      <data key="d0">GitHub (code)</data>
    </node>
    <node id="Du et al.">
      <data key="d0">Du et al.</data>
    </node>
    <node id="Books">
      <data key="d0">Books</data>
    </node>
    <node id="Filtered webpages">
      <data key="d0">Filtered webpages</data>
    </node>
    <node id="duplicate file removal in source code repositories">
      <data key="d0">duplicate file removal in source code repositories</data>
    </node>
    <node id="Lopes et al. (2017)">
      <data key="d0">Lopes et al. (2017)</data>
    </node>
    <node id="Social media conversations">
      <data key="d0">Social media conversations</data>
    </node>
    <node id="Allamanis (2019)">
      <data key="d0">Allamanis (2019)</data>
    </node>
    <node id="Gebru et al.">
      <data key="d0">Gebru et al.</data>
    </node>
    <node id="multilingual corpus">
      <data key="d0">multilingual corpus</data>
    </node>
    <node id="News">
      <data key="d0">News</data>
    </node>
    <node id="Wikipedia">
      <data key="d0">Wikipedia</data>
    </node>
    <node id="datasheet (Appendix D)">
      <data key="d0">datasheet (Appendix D)</data>
    </node>
    <node id="T5X">
      <data key="d0">T5X</data>
    </node>
    <node id="model infrastructure">
      <data key="d0">model infrastructure</data>
    </node>
    <node id="JAX and T5X">
      <data key="d0">JAX and T5X</data>
    </node>
    <node id="training infrastructure">
      <data key="d0">training infrastructure</data>
    </node>
    <node id="Megatron-Turing NLG 530B">
      <data key="d0">Megatron-Turing NLG 530B</data>
    </node>
    <node id="LaMDA (Thoppilan et al., 2022) and GLaM (Du et al., 2021) were each trained on a single TPU system without leveraging either pipeline parallelism or DCN.">
      <data key="d0">LaMDA (Thoppilan et al., 2022) and GLaM (Du et al., 2021) were each trained on a single TPU system without leveraging either pipeline parallelism or DCN.</data>
    </node>
    <node id="A100 GPUs">
      <data key="d0">A100 GPUs</data>
    </node>
    <node id="Pods connected over data center network (DCN) using a combination of model and data parallelism">
      <data key="d0">Pods connected over data center network (DCN) using a combination of model and data parallelism</data>
    </node>
    <node id="TPU system">
      <data key="d0">TPU system</data>
    </node>
    <node id="Xu et al.">
      <data key="d0">Xu et al.</data>
    </node>
    <node id="This system, the largest TPU conﬁguration described to date, allowed us to eﬃciently scale training to 6144 chips without needing to use any pipeline parallelism">
      <data key="d0">This system, the largest TPU conﬁguration described to date, allowed us to eﬃciently scale training to 6144 chips without needing to use any pipeline parallelism</data>
    </node>
    <node id="Huang et al.">
      <data key="d0">Huang et al.</data>
    </node>
    <node id="TPU conﬁguration">
      <data key="d0">TPU conﬁguration</data>
    </node>
    <node id="Rae et al.">
      <data key="d0">Rae et al.</data>
    </node>
    <node id="Megatron-Turing NLG 530B (Smith et al., 2022) was trained on 2240 A100 GPUs using a combination of model, data, and pipeline parallelism,">
      <data key="d0">Megatron-Turing NLG 530B (Smith et al., 2022) was trained on 2240 A100 GPUs using a combination of model, data, and pipeline parallelism,</data>
    </node>
    <node id="researchers">
      <data key="d0">researchers</data>
    </node>
    <node id="Gopher (Rae et al., 2021) was trained on four DCN-connected TPU v3 Pods">
      <data key="d0">Gopher (Rae et al., 2021) was trained on four DCN-connected TPU v3 Pods</data>
    </node>
    <node id="Thoppilan et al.">
      <data key="d0">Thoppilan et al.</data>
    </node>
    <node id="TPU v3 Pods">
      <data key="d0">TPU v3 Pods</data>
    </node>
    <node id="Smith et al.">
      <data key="d0">Smith et al.</data>
    </node>
    <node id="GLaM (Du et al., 2021) were each trained on a single TPU system without leveraging either pipeline parallelism or DCN.">
      <data key="d0">GLaM (Du et al., 2021) were each trained on a single TPU system without leveraging either pipeline parallelism or DCN.</data>
    </node>
    <node id="four DCN-connected TPU v3 Pods">
      <data key="d0">four DCN-connected TPU v3 Pods</data>
    </node>
    <node id="TPU v3 Chips">
      <data key="d0">TPU v3 Chips</data>
    </node>
    <node id="6144 chips">
      <data key="d0">6144 chips</data>
    </node>
    <node id="each weight tensor partitioned over 3072 chips using 12-way model parallelism and 256-way fully sharded data parallelism">
      <data key="d0">each weight tensor partitioned over 3072 chips using 12-way model parallelism and 256-way fully sharded data parallelism</data>
    </node>
    <node id="256-way fully sharded data parallelism">
      <data key="d0">256-way fully sharded data parallelism</data>
    </node>
    <node id="Pathways system">
      <data key="d0">Pathways system</data>
    </node>
    <node id="12-way model parallelism and 256-way fully sharded data parallelism">
      <data key="d0">12-way model parallelism and 256-way fully sharded data parallelism</data>
    </node>
    <node id="TPU v4 Pod">
      <data key="d0">TPU v4 Pod</data>
    </node>
    <node id="fast private interconnects">
      <data key="d0">fast private interconnects</data>
    </node>
    <node id="next timestep">
      <data key="d0">next timestep</data>
    </node>
    <node id="two TPU v4 pods">
      <data key="d0">two TPU v4 pods</data>
    </node>
    <node id="pods">
      <data key="d0">pods</data>
    </node>
    <node id="TPU v4 pods">
      <data key="d0">TPU v4 pods</data>
    </node>
    <node id="remote pod">
      <data key="d0">remote pod</data>
    </node>
    <node id="standard within-pod data and model parallelism">
      <data key="d0">standard within-pod data and model parallelism</data>
    </node>
    <node id="Scheduler (per Pod)">
      <data key="d0">Scheduler (per Pod)</data>
    </node>
    <node id="Host (many per Pod)">
      <data key="d0">Host (many per Pod)</data>
    </node>
    <node id="Model Components">
      <data key="d0">Model Components</data>
    </node>
    <node id="Component B">
      <data key="d0">Component B</data>
    </node>
    <node id="Component A">
      <data key="d0">Component A</data>
    </node>
    <node id="TPU chips">
      <data key="d0">TPU chips</data>
    </node>
    <node id="Optimizer update">
      <data key="d0">Optimizer update</data>
    </node>
    <node id="Datacenter Network">
      <data key="d0">Datacenter Network</data>
    </node>
    <node id="cross-pod gradient transfer">
      <data key="d0">cross-pod gradient transfer</data>
    </node>
    <node id="Transfer subgraph">
      <data key="d0">Transfer subgraph</data>
    </node>
    <node id="Pod 1">
      <data key="d0">Pod 1</data>
    </node>
    <node id="Pod 2">
      <data key="d0">Pod 2</data>
    </node>
    <node id="component B for optimizer update">
      <data key="d0">component B for optimizer update</data>
    </node>
    <node id="corresponding hosts on the two pods">
      <data key="d0">corresponding hosts on the two pods</data>
    </node>
    <node id="Pathways program">
      <data key="d0">Pathways program</data>
    </node>
    <node id="data transfers">
      <data key="d0">data transfers</data>
    </node>
    <node id="hosts between the two pods">
      <data key="d0">hosts between the two pods</data>
    </node>
    <node id="component A">
      <data key="d0">component A</data>
    </node>
    <node id="other pod">
      <data key="d0">other pod</data>
    </node>
    <node id="two pods">
      <data key="d0">two pods</data>
    </node>
    <node id="remote gradients">
      <data key="d0">remote gradients</data>
    </node>
    <node id="hosts">
      <data key="d0">hosts</data>
    </node>
    <node id="remote servers">
      <data key="d0">remote servers</data>
    </node>
    <node id="component B">
      <data key="d0">component B</data>
    </node>
    <node id="JAX/XLA work">
      <data key="d0">JAX/XLA work</data>
    </node>
    <node id="model-sharded parameters">
      <data key="d0">model-sharded parameters</data>
    </node>
    <node id="sharded-data flow execution model">
      <data key="d0">sharded-data flow execution model</data>
    </node>
    <node id="Google datacenter network">
      <data key="d0">Google datacenter network</data>
    </node>
    <node id="gradient transfers">
      <data key="d0">gradient transfers</data>
    </node>
    <node id="1:1 transfer between corresponding hosts on two pods">
      <data key="d0">1:1 transfer between corresponding hosts on two pods</data>
    </node>
    <node id="Pathways networking stack">
      <data key="d0">Pathways networking stack</data>
    </node>
    <node id="optimal DCN link utilization">
      <data key="d0">optimal DCN link utilization</data>
    </node>
    <node id="81 Tbps across all hosts">
      <data key="d0">81 Tbps across all hosts</data>
    </node>
    <node id="hosts between two pods">
      <data key="d0">hosts between two pods</data>
    </node>
    <node id="approximately 1.3 GB of gradients">
      <data key="d0">approximately 1.3 GB of gradients</data>
    </node>
    <node id="each pair of hosts">
      <data key="d0">each pair of hosts</data>
    </node>
    <node id="1.95x">
      <data key="d0">1.95x</data>
    </node>
    <node id="Scaling Language Modeling">
      <data key="d0">Scaling Language Modeling</data>
    </node>
    <node id="Gradient Transfers">
      <data key="d0">Gradient Transfers</data>
    </node>
    <node id="DCN links">
      <data key="d0">DCN links</data>
    </node>
    <node id="Optimizations">
      <data key="d0">Optimizations</data>
    </node>
    <node id="Language Models">
      <data key="d0">Language Models</data>
    </node>
    <node id="stack">
      <data key="d0">stack</data>
    </node>
    <node id="the ratio of FLOPs observed on a given device to its theoretical peak FLOPs">
      <data key="d0">the ratio of FLOPs observed on a given device to its theoretical peak FLOPs</data>
    </node>
    <node id="Hardware FLOPs utilization">
      <data key="d0">Hardware FLOPs utilization</data>
    </node>
    <node id="FLOPs utilization (HFU)">
      <data key="d0">FLOPs utilization (HFU)</data>
    </node>
    <node id="system-dependent and implementation-dependent design choices in the compiler can result in different number of operations">
      <data key="d0">system-dependent and implementation-dependent design choices in the compiler can result in different number of operations</data>
    </node>
    <node id="Backwards pass of most neural network architectures using gradient descent">
      <data key="d0">Backwards pass of most neural network architectures using gradient descent</data>
    </node>
    <node id="memory usage with compute">
      <data key="d0">memory usage with compute</data>
    </node>
    <node id="Hardware FLOPs">
      <data key="d0">Hardware FLOPs</data>
    </node>
    <node id="Training system">
      <data key="d0">Training system</data>
    </node>
    <node id="many intermediate activations for the batch must be stored in memory">
      <data key="d0">many intermediate activations for the batch must be stored in memory</data>
    </node>
    <node id="Methodology used to count or track hardware FLOPs">
      <data key="d0">Methodology used to count or track hardware FLOPs</data>
    </node>
    <node id="achieve a high throughput in tokens per second">
      <data key="d0">achieve a high throughput in tokens per second</data>
    </node>
    <node id="observed hardware FLOPs">
      <data key="d0">observed hardware FLOPs</data>
    </node>
    <node id="FLOPs">
      <data key="d0">FLOPs</data>
    </node>
    <node id="some forward pass operations can be re-computed (enabling some activations to be rematerialized rather than stored)">
      <data key="d0">some forward pass operations can be re-computed (enabling some activations to be rematerialized rather than stored)</data>
    </node>
    <node id="Rematerialization">
      <data key="d0">Rematerialization</data>
    </node>
    <node id="analytical accounting">
      <data key="d0">analytical accounting</data>
    </node>
    <node id="forward+backward passes">
      <data key="d0">forward+backward passes</data>
    </node>
    <node id="tokens per second">
      <data key="d0">tokens per second</data>
    </node>
    <node id="hardware performance counters">
      <data key="d0">hardware performance counters</data>
    </node>
    <node id="MFU">
      <data key="d0">MFU</data>
    </node>
    <node id="system efficiency">
      <data key="d0">system efficiency</data>
    </node>
    <node id="theoretical maximum throughput">
      <data key="d0">theoretical maximum throughput</data>
    </node>
    <node id="LLM training efficiency">
      <data key="d0">LLM training efficiency</data>
    </node>
    <node id="memory">
      <data key="d0">memory</data>
    </node>
    <node id="HFU">
      <data key="d0">HFU</data>
    </node>
    <node id="Observed hardware FLOPs">
      <data key="d0">Observed hardware FLOPs</data>
    </node>
    <node id="comparing models and systems">
      <data key="d0">comparing models and systems</data>
    </node>
    <node id="Patterson et al.">
      <data key="d0">Patterson et al.</data>
    </node>
    <node id="65.43K tokens/sec">
      <data key="d0">65.43K tokens/sec</data>
    </node>
    <node id="higher feasible batch size">
      <data key="d0">higher feasible batch size</data>
    </node>
    <node id="GPT-3 model">
      <data key="d0">GPT-3 model</data>
    </node>
    <node id="GPT-3 and Gopher models">
      <data key="d0">GPT-3 and Gopher models</data>
    </node>
    <node id="29.7%">
      <data key="d0">29.7%</data>
    </node>
    <node id="57.8%">
      <data key="d0">57.8%</data>
    </node>
    <node id="prior large models">
      <data key="d0">prior large models</data>
    </node>
    <node id="training throughput and model quality">
      <data key="d0">training throughput and model quality</data>
    </node>
    <node id="OpenAI">
      <data key="d0">OpenAI</data>
    </node>
    <node id="PaLM 540B model">
      <data key="d0">PaLM 540B model</data>
    </node>
    <node id="Gopher model">
      <data key="d0">Gopher model</data>
    </node>
    <node id="Megatron–Turing NLG 530B model">
      <data key="d0">Megatron–Turing NLG 530B model</data>
    </node>
    <node id="45.7%">
      <data key="d0">45.7%</data>
    </node>
    <node id="238.3K tokens/sec">
      <data key="d0">238.3K tokens/sec</data>
    </node>
    <node id="32.5%">
      <data key="d0">32.5%</data>
    </node>
    <node id="21.3%">
      <data key="d0">21.3%</data>
    </node>
    <node id="Megatron LM">
      <data key="d0">Megatron LM</data>
    </node>
    <node id="3Gopher">
      <data key="d0">3Gopher</data>
    </node>
    <node id="0.0152 steps per second">
      <data key="d0">0.0152 steps per second</data>
    </node>
    <node id="Narayanan et al.">
      <data key="d0">Narayanan et al.</data>
    </node>
    <node id="Earlier Benchmark Numbers">
      <data key="d0">Earlier Benchmark Numbers</data>
    </node>
    <node id="XLA TPU Compiler Optimizations">
      <data key="d0">XLA TPU Compiler Optimizations</data>
    </node>
    <node id="2021b">
      <data key="d0">2021b</data>
    </node>
    <node id="High Accelerator Utilization">
      <data key="d0">High Accelerator Utilization</data>
    </node>
    <node id="Input embeddings">
      <data key="d0">Input embeddings</data>
    </node>
    <node id="'standard setup for large Transformer language models'">
      <data key="d0">'standard setup for large Transformer language models'</data>
    </node>
    <node id="'N(0,1)'">
      <data key="d0">'N(0,1)'</data>
    </node>
    <node id="Model training">
      <data key="d0">Model training</data>
    </node>
    <node id="Kernel weights">
      <data key="d0">Kernel weights</data>
    </node>
    <node id="Narayanan et al. (2021b)">
      <data key="d0">Narayanan et al. (2021b)</data>
    </node>
    <node id="'fan-in variance scaling'">
      <data key="d0">'fan-in variance scaling'</data>
    </node>
    <node id="Weight initialization">
      <data key="d0">Weight initialization</data>
    </node>
    <node id="Pre-softmax output logits">
      <data key="d0">Pre-softmax output logits</data>
    </node>
    <node id="1 /√n">
      <data key="d0">1 /√n</data>
    </node>
    <node id="Adafactor">
      <data key="d0">Adafactor</data>
    </node>
    <node id="global norm gradient clipping">
      <data key="d0">global norm gradient clipping</data>
    </node>
    <node id="Pascanu et al.">
      <data key="d0">Pascanu et al.</data>
    </node>
    <node id="β1= 0.9">
      <data key="d0">β1= 0.9</data>
    </node>
    <node id="10−2">
      <data key="d0">10−2</data>
    </node>
    <node id="Brown et al.">
      <data key="d0">Brown et al.</data>
    </node>
    <node id="10−2for the ﬁrst 10,000 steps">
      <data key="d0">10−2for the ﬁrst 10,000 steps</data>
    </node>
    <node id="Adam">
      <data key="d0">Adam</data>
    </node>
    <node id="label smoothing">
      <data key="d0">label smoothing</data>
    </node>
    <node id="large language models">
      <data key="d0">large language models</data>
    </node>
    <node id="the largest model">
      <data key="d0">the largest model</data>
    </node>
    <node id="rare embedding tokens">
      <data key="d0">rare embedding tokens</data>
    </node>
    <node id="step 50k">
      <data key="d0">step 50k</data>
    </node>
    <node id="poorly estimated second moments">
      <data key="d0">poorly estimated second moments</data>
    </node>
    <node id="all models">
      <data key="d0">all models</data>
    </node>
    <node id="batch size">
      <data key="d0">batch size</data>
    </node>
    <node id="the model">
      <data key="d0">the model</data>
    </node>
    <node id="average log probability">
      <data key="d0">average log probability</data>
    </node>
    <node id="step 115k">
      <data key="d0">step 115k</data>
    </node>
    <node id="standard language modeling loss function">
      <data key="d0">standard language modeling loss function</data>
    </node>
    <node id="tokens">
      <data key="d0">tokens</data>
    </node>
    <node id="padding tokens">
      <data key="d0">padding tokens</data>
    </node>
    <node id="lr">
      <data key="d0">lr</data>
    </node>
    <node id="sequences">
      <data key="d0">sequences</data>
    </node>
    <node id="dynamic weight decay">
      <data key="d0">dynamic weight decay</data>
    </node>
    <node id="sequence length">
      <data key="d0">sequence length</data>
    </node>
    <node id="all tokens">
      <data key="d0">all tokens</data>
    </node>
    <node id="value of 1.0">
      <data key="d0">value of 1.0</data>
    </node>
    <node id="2018">
      <data key="d0">2018</data>
    </node>
    <node id="large batch size schedule">
      <data key="d0">large batch size schedule</data>
    </node>
    <node id="bitwise determinism">
      <data key="d0">bitwise determinism</data>
    </node>
    <node id="McCandlish et al.">
      <data key="d0">McCandlish et al.</data>
    </node>
    <node id="Bitwise determinism">
      <data key="d0">Bitwise determinism</data>
    </node>
    <node id="Training Instability">
      <data key="d0">Training Instability</data>
    </node>
    <node id="Deterministic dataset pipeline">
      <data key="d0">Deterministic dataset pipeline</data>
    </node>
    <node id="Dropout">
      <data key="d0">Dropout</data>
    </node>
    <node id="JAX+XLA+T5X">
      <data key="d0">JAX+XLA+T5X</data>
    </node>
    <node id="TPU">
      <data key="d0">TPU</data>
    </node>
    <node id="Smaller models">
      <data key="d0">Smaller models</data>
    </node>
    <node id="Bad Data">
      <data key="d0">Bad Data</data>
    </node>
    <node id="Restarting Training">
      <data key="d0">Restarting Training</data>
    </node>
    <node id="Gradient Clipping">
      <data key="d0">Gradient Clipping</data>
    </node>
    <node id="Loss Spikes">
      <data key="d0">Loss Spikes</data>
    </node>
    <node id="Open-Domain Closed-Book Question Answering tasks">
      <data key="d0">Open-Domain Closed-Book Question Answering tasks</data>
    </node>
    <node id="Other large language models">
      <data key="d0">Other large language models</data>
    </node>
    <node id="TriviaQA (Joshi et al., 2017)">
      <data key="d0">TriviaQA (Joshi et al., 2017)</data>
    </node>
    <node id="Natural Questions (Kwiatkowski et al., 2019)">
      <data key="d0">Natural Questions (Kwiatkowski et al., 2019)</data>
    </node>
    <node id="Prior state-of-the-art results from other large language models">
      <data key="d0">Prior state-of-the-art results from other large language models</data>
    </node>
    <node id="Web Questions (Berant et al., 2013)">
      <data key="d0">Web Questions (Berant et al., 2013)</data>
    </node>
    <node id="Reading Comprehension and NLI tasks">
      <data key="d0">Reading Comprehension and NLI tasks</data>
    </node>
    <node id="Prior SOTA results">
      <data key="d0">Prior SOTA results</data>
    </node>
    <node id="Natural Questions">
      <data key="d0">Natural Questions</data>
    </node>
    <node id="GPT-3 175B">
      <data key="d0">GPT-3 175B</data>
    </node>
    <node id="Natural Language Understanding (NLU)">
      <data key="d0">Natural Language Understanding (NLU)</data>
    </node>
    <node id="Natural Language Generation (NLG)">
      <data key="d0">Natural Language Generation (NLG)</data>
    </node>
    <node id="TriviaQA">
      <data key="d0">TriviaQA</data>
    </node>
    <node id="Natural Questions (EM)">
      <data key="d0">Natural Questions (EM)</data>
    </node>
    <node id="Web Questions (EM)">
      <data key="d0">Web Questions (EM)</data>
    </node>
    <node id="HellaSwag">
      <data key="d0">HellaSwag</data>
    </node>
    <node id="Winograd">
      <data key="d0">Winograd</data>
    </node>
    <node id="84.0b79.9">
      <data key="d0">84.0b79.9</data>
    </node>
    <node id="71.8a 83.3">
      <data key="d0">71.8a 83.3</data>
    </node>
    <node id="67.0a 79.6">
      <data key="d0">67.0a 79.6</data>
    </node>
    <node id="Prior SOTAPaLM 540B">
      <data key="d0">Prior SOTAPaLM 540B</data>
    </node>
    <node id="81.5b77.6">
      <data key="d0">81.5b77.6</data>
    </node>
    <node id="58.6a 70.8">
      <data key="d0">58.6a 70.8</data>
    </node>
    <node id="Winogrande">
      <data key="d0">Winogrande</data>
    </node>
    <node id="SOTAPaLM 540B">
      <data key="d0">SOTAPaLM 540B</data>
    </node>
    <node id="TriviaQA (EM)">
      <data key="d0">TriviaQA (EM)</data>
    </node>
    <node id="85.0b 81.5">
      <data key="d0">85.0b 81.5</data>
    </node>
    <node id="57.8a70.8">
      <data key="d0">57.8a70.8</data>
    </node>
    <node id="64.7a75.5">
      <data key="d0">64.7a75.5</data>
    </node>
    <node id="StoryCloze">
      <data key="d0">StoryCloze</data>
    </node>
    <node id="Lambada (EM)">
      <data key="d0">Lambada (EM)</data>
    </node>
    <node id="71.1a80.8">
      <data key="d0">71.1a80.8</data>
    </node>
    <node id="57.3a69.4">
      <data key="d0">57.3a69.4</data>
    </node>
    <node id="66.5a78.7">
      <data key="d0">66.5a78.7</data>
    </node>
    <node id="71.8a82.9">
      <data key="d0">71.8a82.9</data>
    </node>
    <node id="GLaM 62B/64E">
      <data key="d0">GLaM 62B/64E</data>
    </node>
    <node id="RACE-h">
      <data key="d0">RACE-h</data>
    </node>
    <node id="Table 5: Average (Avg) Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.">
      <data key="d0">Table 5: Average (Avg) Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.</data>
    </node>
    <node id="58 .4">
      <data key="d0">58 .4</data>
    </node>
    <node id="41 .5">
      <data key="d0">41 .5</data>
    </node>
    <node id="57 .7">
      <data key="d0">57 .7</data>
    </node>
    <node id="RACE-m/h">
      <data key="d0">RACE-m/h</data>
    </node>
    <node id="Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.">
      <data key="d0">Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.</data>
    </node>
    <node id="GPT-3 and other large LMs">
      <data key="d0">GPT-3 and other large LMs</data>
    </node>
    <node id="MMLU benchmark">
      <data key="d0">MMLU benchmark</data>
    </node>
    <node id="Chinchilla model">
      <data key="d0">Chinchilla model</data>
    </node>
    <node id="ST-MoE-32B">
      <data key="d0">ST-MoE-32B</data>
    </node>
    <node id="SuperGLUE benchmark">
      <data key="d0">SuperGLUE benchmark</data>
    </node>
    <node id="PaLM model">
      <data key="d0">PaLM model</data>
    </node>
    <node id="T5-11B">
      <data key="d0">T5-11B</data>
    </node>
    <node id="autoregressive decoder-only models">
      <data key="d0">autoregressive decoder-only models</data>
    </node>
    <node id="less than 15K steps">
      <data key="d0">less than 15K steps</data>
    </node>
    <node id="finetuned results">
      <data key="d0">finetuned results</data>
    </node>
    <node id="competitive close-to-SOTA performance">
      <data key="d0">competitive close-to-SOTA performance</data>
    </node>
    <node id="few-shot results">
      <data key="d0">few-shot results</data>
    </node>
    <node id="encoder-decoder models">
      <data key="d0">encoder-decoder models</data>
    </node>
    <node id="State-of-the-art span corruption based Encoder-Decoder">
      <data key="d0">State-of-the-art span corruption based Encoder-Decoder</data>
    </node>
    <node id="PaLM-540B (finetuned)">
      <data key="d0">PaLM-540B (finetuned)</data>
    </node>
    <node id="over 150 tasks">
      <data key="d0">over 150 tasks</data>
    </node>
    <node id="PaLM model family">
      <data key="d0">PaLM model family</data>
    </node>
    <node id="Best Decoder-only LM">
      <data key="d0">Best Decoder-only LM</data>
    </node>
    <node id="PaLM-540B">
      <data key="d0">PaLM-540B</data>
    </node>
    <node id="workers (typically 10)">
      <data key="d0">workers (typically 10)</data>
    </node>
    <node id="BIG-bench data release">
      <data key="d0">BIG-bench data release</data>
    </node>
    <node id="gold labels">
      <data key="d0">gold labels</data>
    </node>
    <node id="crowdsourcing platform">
      <data key="d0">crowdsourcing platform</data>
    </node>
    <node id="human performance metrics">
      <data key="d0">human performance metrics</data>
    </node>
    <node id="each task">
      <data key="d0">each task</data>
    </node>
    <node id="PaLM family of models">
      <data key="d0">PaLM family of models</data>
    </node>
    <node id="prior SOTA">
      <data key="d0">prior SOTA</data>
    </node>
    <node id="humans">
      <data key="d0">humans</data>
    </node>
    <node id="higher score than the average score of humans">
      <data key="d0">higher score than the average score of humans</data>
    </node>
    <node id="https://github.com/google/BIG-bench">
      <data key="d0">https://github.com/google/BIG-bench</data>
    </node>
    <node id="performance as a function of scale">
      <data key="d0">performance as a function of scale</data>
    </node>
    <node id="PaLM 540B 5-shot">
      <data key="d0">PaLM 540B 5-shot</data>
    </node>
    <node id="PaLM models">
      <data key="d0">PaLM models</data>
    </node>
    <node id="Prior SOTA">
      <data key="d0">Prior SOTA</data>
    </node>
    <node id="passage">
      <data key="d0">passage</data>
    </node>
    <node id="goal step wikihow">
      <data key="d0">goal step wikihow</data>
    </node>
    <node id="logical args">
      <data key="d0">logical args</data>
    </node>
    <node id="events">
      <data key="d0">events</data>
    </node>
    <node id="Scaling Language Modeling with Pathways">
      <data key="d0">Scaling Language Modeling with Pathways</data>
    </node>
    <node id="job">
      <data key="d0">job</data>
    </node>
    <node id="months">
      <data key="d0">months</data>
    </node>
    <node id="drink water, feel thirsty, seal water bottle, open water bottle">
      <data key="d0">drink water, feel thirsty, seal water bottle, open water bottle</data>
    </node>
    <node id="location">
      <data key="d0">location</data>
    </node>
    <node id="center">
      <data key="d0">center</data>
    </node>
    <node id="local center for homeless aid">
      <data key="d0">local center for homeless aid</data>
    </node>
    <node id="Vanessa">
      <data key="d0">Vanessa</data>
    </node>
    <node id="feel thirsty, open water bottle, drink water, seal water bottle">
      <data key="d0">feel thirsty, open water bottle, drink water, seal water bottle</data>
    </node>
    <node id="logical inference rules">
      <data key="d0">logical inference rules</data>
    </node>
    <node id="drink water">
      <data key="d0">drink water</data>
    </node>
    <node id="mathematical induction">
      <data key="d0">mathematical induction</data>
    </node>
    <node id="water bottle">
      <data key="d0">water bottle</data>
    </node>
    <node id="bottle">
      <data key="d0">bottle</data>
    </node>
    <node id="seal water bottle">
      <data key="d0">seal water bottle</data>
    </node>
    <node id="navigate">
      <data key="d0">navigate</data>
    </node>
    <node id="figure out where you would end up">
      <data key="d0">figure out where you would end up</data>
    </node>
    <node id="open water bottle">
      <data key="d0">open water bottle</data>
    </node>
    <node id="feel thirsty">
      <data key="d0">feel thirsty</data>
    </node>
    <node id="english proverbs">
      <data key="d0">english proverbs</data>
    </node>
    <node id="wikihow">
      <data key="d0">wikihow</data>
    </node>
    <node id="PaLM 8b">
      <data key="d0">PaLM 8b</data>
    </node>
    <node id="high level of abstract reasoning capability">
      <data key="d0">high level of abstract reasoning capability</data>
    </node>
    <node id="log-linear projection using 8b →62b">
      <data key="d0">log-linear projection using 8b →62b</data>
    </node>
    <node id="logical sequence task">
      <data key="d0">logical sequence task</data>
    </node>
    <node id="PaLM 62b">
      <data key="d0">PaLM 62b</data>
    </node>
    <node id="log-linear improvements">
      <data key="d0">log-linear improvements</data>
    </node>
    <node id="TRAINING_CORPORA">
      <data key="d0">TRAINING_CORPORA</data>
    </node>
    <node id="BENCHMARK_DATA">
      <data key="d0">BENCHMARK_DATA</data>
    </node>
    <node id="Figure 5">
      <data key="d0">Figure 5</data>
    </node>
    <node id="relatively flat improvements">
      <data key="d0">relatively flat improvements</data>
    </node>
    <node id="Persian Idioms">
      <data key="d0">Persian Idioms</data>
    </node>
    <node id="human asked to solve the task">
      <data key="d0">human asked to solve the task</data>
    </node>
    <node id="average human performance">
      <data key="d0">average human performance</data>
    </node>
    <node id="Swedish to German Proverbs">
      <data key="d0">Swedish to German Proverbs</data>
    </node>
    <node id="Periodic Elements">
      <data key="d0">Periodic Elements</data>
    </node>
    <node id="Human">
      <data key="d0">Human</data>
    </node>
    <node id="Logical Args">
      <data key="d0">Logical Args</data>
    </node>
    <node id="Sufficient Information">
      <data key="d0">Sufficient Information</data>
    </node>
    <node id="Cause and Effect Task">
      <data key="d0">Cause and Effect Task</data>
    </node>
    <node id="Common Morpheme">
      <data key="d0">Common Morpheme</data>
    </node>
    <node id="cause andeﬀect">
      <data key="d0">cause andeﬀect</data>
    </node>
    <node id="I washed the car because my car got dirty.">
      <data key="d0">I washed the car because my car got dirty.</data>
    </node>
    <node id="My car got dirty because I washed the car.">
      <data key="d0">My car got dirty because I washed the car.</data>
    </node>
    <node id="cause andeﬀect (two sentence)">
      <data key="d0">cause andeﬀect (two sentence)</data>
    </node>
    <node id="Figure 6">
      <data key="d0">Figure 6</data>
    </node>
    <node id="Human (Avg.)">
      <data key="d0">Human (Avg.)</data>
    </node>
    <node id="PaLM 540b">
      <data key="d0">PaLM 540b</data>
    </node>
    <node id="cause andeﬀect (one sentence noprompt)">
      <data key="d0">cause andeﬀect (one sentence noprompt)</data>
    </node>
    <node id="BIG-bench Tasks">
      <data key="d0">BIG-bench Tasks</data>
    </node>
    <node id="80%">
      <data key="d0">80%</data>
    </node>
    <node id="BIG-bench Lite">
      <data key="d0">BIG-bench Lite</data>
    </node>
    <node id="twosentence version of the task">
      <data key="d0">twosentence version of the task</data>
    </node>
    <node id="90%">
      <data key="d0">90%</data>
    </node>
    <node id="t12: logical deduction">
      <data key="d0">t12: logical deduction</data>
    </node>
    <node id="t8: hindu knowledge">
      <data key="d0">t8: hindu knowledge</data>
    </node>
    <node id="t6: emoji movie">
      <data key="d0">t6: emoji movie</data>
    </node>
    <node id="t17: play dialog same ordiﬀerent">
      <data key="d0">t17: play dialog same ordiﬀerent</data>
    </node>
    <node id="t13: misconceptions russian">
      <data key="d0">t13: misconceptions russian</data>
    </node>
    <node id="t4: conceptual combinations">
      <data key="d0">t4: conceptual combinations</data>
    </node>
    <node id="t14: novel concepts">
      <data key="d0">t14: novel concepts</data>
    </node>
    <node id="t7: formal fallacies syllogisms negation">
      <data key="d0">t7: formal fallacies syllogisms negation</data>
    </node>
    <node id="540B model">
      <data key="d0">540B model</data>
    </node>
    <node id="t15: operators">
      <data key="d0">t15: operators</data>
    </node>
    <node id="t11: logic gridpuzzle">
      <data key="d0">t11: logic gridpuzzle</data>
    </node>
    <node id="t1: auto debugging">
      <data key="d0">t1: auto debugging</data>
    </node>
    <node id="t16: parsinlu reading comprehension">
      <data key="d0">t16: parsinlu reading comprehension</data>
    </node>
    <node id="t10: language identiﬀcation">
      <data key="d0">t10: language identiﬀcation</data>
    </node>
    <node id="t5: conlang translation">
      <data key="d0">t5: conlang translation</data>
    </node>
    <node id="8B model">
      <data key="d0">8B model</data>
    </node>
    <node id="t9: known unknowns">
      <data key="d0">t9: known unknowns</data>
    </node>
    <node id="t2: bbq litejson">
      <data key="d0">t2: bbq litejson</data>
    </node>
    <node id="t3: code linedescription">
      <data key="d0">t3: code linedescription</data>
    </node>
    <node id="t18: repeat copy logic">
      <data key="d0">t18: repeat copy logic</data>
    </node>
    <node id="3 tasks">
      <data key="d0">3 tasks</data>
    </node>
    <node id="Task t24">
      <data key="d0">Task t24</data>
    </node>
    <node id="Best human performance score">
      <data key="d0">Best human performance score</data>
    </node>
    <node id="Both PaLM 540B and human performance scores">
      <data key="d0">Both PaLM 540B and human performance scores</data>
    </node>
    <node id="All model scales">
      <data key="d0">All model scales</data>
    </node>
    <node id="training data">
      <data key="d0">training data</data>
    </node>
    <node id="Gold Labels">
      <data key="d0">Gold Labels</data>
    </node>
    <node id="Arithmetic Reasoning">
      <data key="d0">Arithmetic Reasoning</data>
    </node>
    <node id="Rae Et Al">
      <data key="d0">Rae Et Al</data>
    </node>
    <node id="None">
      <data key="d0">None</data>
    </node>
    <node id="11 tennis balls">
      <data key="d0">11 tennis balls</data>
    </node>
    <node id="multi-step reasoning">
      <data key="d0">multi-step reasoning</data>
    </node>
    <node id="2021">
      <data key="d0">2021</data>
    </node>
    <node id="reasoning tasks">
      <data key="d0">reasoning tasks</data>
    </node>
    <node id="Natural Language Math Problems">
      <data key="d0">Natural Language Math Problems</data>
    </node>
    <node id="Model">
      <data key="d0">Model</data>
    </node>
    <node id="Roger">
      <data key="d0">Roger</data>
    </node>
    <node id="2 cans of tennis balls">
      <data key="d0">2 cans of tennis balls</data>
    </node>
    <node id="5 tennis balls">
      <data key="d0">5 tennis balls</data>
    </node>
    <node id="slow down">
      <data key="d0">slow down</data>
    </node>
    <node id="11">
      <data key="d0">11</data>
    </node>
    <node id="home">
      <data key="d0">home</data>
    </node>
    <node id="3 tennis balls per can">
      <data key="d0">3 tennis balls per can</data>
    </node>
    <node id="Sean">
      <data key="d0">Sean</data>
    </node>
    <node id="5">
      <data key="d0">5</data>
    </node>
    <node id="Chain-of-thought prompting">
      <data key="d0">Chain-of-thought prompting</data>
    </node>
    <node id="Cobbe et al. (2021)">
      <data key="d0">Cobbe et al. (2021)</data>
    </node>
    <node id="Nye et al. (2021)">
      <data key="d0">Nye et al. (2021)</data>
    </node>
    <node id="Wei et al. (2022b)">
      <data key="d0">Wei et al. (2022b)</data>
    </node>
    <node id="arithmetic datasets GSM8K">
      <data key="d0">arithmetic datasets GSM8K</data>
    </node>
    <node id="post-hoc external calculator">
      <data key="d0">post-hoc external calculator</data>
    </node>
    <node id="chain-of-thought prompting">
      <data key="d0">chain-of-thought prompting</data>
    </node>
    <node id="SOTA accuracy across a variety of arithmetic and commonsense reasoning tasks">
      <data key="d0">SOTA accuracy across a variety of arithmetic and commonsense reasoning tasks</data>
    </node>
    <node id="Cobbe et al.">
      <data key="d0">Cobbe et al.</data>
    </node>
    <node id="58%">
      <data key="d0">58%</data>
    </node>
    <node id="model predictions">
      <data key="d0">model predictions</data>
    </node>
    <node id="common sense reasoning datasets">
      <data key="d0">common sense reasoning datasets</data>
    </node>
    <node id="CommonsenseQA">
      <data key="d0">CommonsenseQA</data>
    </node>
    <node id="external calculator">
      <data key="d0">external calculator</data>
    </node>
    <node id="PaLM 540B w/o chain-of-thought">
      <data key="d0">PaLM 540B w/o chain-of-thought</data>
    </node>
    <node id="StrategyQA">
      <data key="d0">StrategyQA</data>
    </node>
    <node id="scaling up to the 540B model size">
      <data key="d0">scaling up to the 540B model size</data>
    </node>
    <node id="33%">
      <data key="d0">33%</data>
    </node>
    <node id="20 errors of semantic understanding">
      <data key="d0">20 errors of semantic understanding</data>
    </node>
    <node id="55%">
      <data key="d0">55%</data>
    </node>
    <node id="PaLM 540B+chain-of-thought">
      <data key="d0">PaLM 540B+chain-of-thought</data>
    </node>
    <node id="8-shot chain-of-thought prompting">
      <data key="d0">8-shot chain-of-thought prompting</data>
    </node>
    <node id="34%">
      <data key="d0">34%</data>
    </node>
    <node id="PaLM 62B+chain-of-thought">
      <data key="d0">PaLM 62B+chain-of-thought</data>
    </node>
    <node id="PaLM 540B+chain-of-thought+calculator">
      <data key="d0">PaLM 540B+chain-of-thought+calculator</data>
    </node>
    <node id="PaLM 64B">
      <data key="d0">PaLM 64B</data>
    </node>
    <node id="GSM8K">
      <data key="d0">GSM8K</data>
    </node>
    <node id="intermediate reasoning steps">
      <data key="d0">intermediate reasoning steps</data>
    </node>
    <node id="AQuA">
      <data key="d0">AQuA</data>
    </node>
    <node id="SVAMP">
      <data key="d0">SVAMP</data>
    </node>
    <node id="MAWPS">
      <data key="d0">MAWPS</data>
    </node>
    <node id="accuracy">
      <data key="d0">accuracy</data>
    </node>
    <node id="PaLM results">
      <data key="d0">PaLM results</data>
    </node>
    <node id="ASDiv">
      <data key="d0">ASDiv</data>
    </node>
    <node id="Chain-of-Thought Prompting">
      <data key="d0">Chain-of-Thought Prompting</data>
    </node>
    <node id="Model Scaling">
      <data key="d0">Model Scaling</data>
    </node>
    <node id="Lan et al.">
      <data key="d0">Lan et al.</data>
    </node>
    <node id="Talmor et al.">
      <data key="d0">Talmor et al.</data>
    </node>
    <node id="Piekos et al.">
      <data key="d0">Piekos et al.</data>
    </node>
    <node id="Pi et al.">
      <data key="d0">Pi et al.</data>
    </node>
    <node id="Geva et al.">
      <data key="d0">Geva et al.</data>
    </node>
    <node id="code completion">
      <data key="d0">code completion</data>
    </node>
    <node id="coding tasks">
      <data key="d0">coding tasks</data>
    </node>
    <node id="MBPP dataset">
      <data key="d0">MBPP dataset</data>
    </node>
    <node id="HumanEval dataset">
      <data key="d0">HumanEval dataset</data>
    </node>
    <node id="Li et al.">
      <data key="d0">Li et al.</data>
    </node>
    <node id="Chen et al.">
      <data key="d0">Chen et al.</data>
    </node>
    <node id="program synthesis from natural language specifications">
      <data key="d0">program synthesis from natural language specifications</data>
    </node>
    <node id="GSM8K-Python task">
      <data key="d0">GSM8K-Python task</data>
    </node>
    <node id="Austin et al.">
      <data key="d0">Austin et al.</data>
    </node>
    <node id="competitive programming">
      <data key="d0">competitive programming</data>
    </node>
    <node id="GSM8K dataset">
      <data key="d0">GSM8K dataset</data>
    </node>
    <node id="notes = 'o o| .| o| o| .| .| o o'">
      <data key="d0">notes = 'o o| .| o| o| .| .| o o'</data>
    </node>
    <node id=" musical notes string">
      <data key="d0"> musical notes string</data>
    </node>
    <node id="few-shot prompts">
      <data key="d0">few-shot prompts</data>
    </node>
    <node id="test set">
      <data key="d0">test set</data>
    </node>
    <node id="modify programs so that they compile successfully">
      <data key="d0">modify programs so that they compile successfully</data>
    </node>
    <node id="DeepFix (Gupta et al., 2017)">
      <data key="d0">DeepFix (Gupta et al., 2017)</data>
    </node>
    <node id="Yasunaga &amp; Liang (2020, 2021)">
      <data key="d0">Yasunaga &amp; Liang (2020, 2021)</data>
    </node>
    <node id="compiler errors">
      <data key="d0">compiler errors</data>
    </node>
    <node id="Gupta et al. (2017)">
      <data key="d0">Gupta et al. (2017)</data>
    </node>
    <node id="1260 programs">
      <data key="d0">1260 programs</data>
    </node>
    <node id="box of pizza">
      <data key="d0">box of pizza</data>
    </node>
    <node id="milk">
      <data key="d0">milk</data>
    </node>
    <node id="chicken meal">
      <data key="d0">chicken meal</data>
    </node>
    <node id="pizza">
      <data key="d0">pizza</data>
    </node>
    <node id="Marie">
      <data key="d0">Marie</data>
    </node>
    <node id="apples">
      <data key="d0">apples</data>
    </node>
    <node id="cost_of_meal">
      <data key="d0">cost_of_meal</data>
    </node>
    <node id="i">
      <data key="d0">i</data>
    </node>
    <node id="sm">
      <data key="d0">sm</data>
    </node>
    <node id="cost_of_pizza_per_box">
      <data key="d0">cost_of_pizza_per_box</data>
    </node>
    <node id="1">
      <data key="d0">1</data>
    </node>
    <node id="0">
      <data key="d0">0</data>
    </node>
    <node id="3">
      <data key="d0">3</data>
    </node>
    <node id="def sum_pairwise_products (n):">
      <data key="d0">def sum_pairwise_products (n):</data>
    </node>
    <node id="cost_of_apples_per_apple">
      <data key="d0">cost_of_apples_per_apple</data>
    </node>
    <node id="1.50">
      <data key="d0">1.50</data>
    </node>
    <node id="sum_pairwise_products">
      <data key="d0">sum_pairwise_products</data>
    </node>
    <node id="j">
      <data key="d0">j</data>
    </node>
    <node id="cost_of_milk_per_pack">
      <data key="d0">cost_of_milk_per_pack</data>
    </node>
    <node id="packages_of_milk">
      <data key="d0">packages_of_milk</data>
    </node>
    <node id="int n)">
      <data key="d0">int n)</data>
    </node>
    <node id="total_paid">
      <data key="d0">total_paid</data>
    </node>
    <node id="Kulal et al.">
      <data key="d0">Kulal et al.</data>
    </node>
    <node id="pass@ kmetric">
      <data key="d0">pass@ kmetric</data>
    </node>
    <node id="LaMDA 137B parameter model">
      <data key="d0">LaMDA 137B parameter model</data>
    </node>
    <node id="MBPP">
      <data key="d0">MBPP</data>
    </node>
    <node id="TransCoder">
      <data key="d0">TransCoder</data>
    </node>
    <node id="HumanEval">
      <data key="d0">HumanEval</data>
    </node>
    <node id="GSM8K math dataset">
      <data key="d0">GSM8K math dataset</data>
    </node>
    <node id="C++ to Python translation">
      <data key="d0">C++ to Python translation</data>
    </node>
    <node id="pass@ kestimator">
      <data key="d0">pass@ kestimator</data>
    </node>
    <node id="High (Austin et al., 2021)">
      <data key="d0">High (Austin et al., 2021)</data>
    </node>
    <node id="Researchers (Thoppilan et al., 2022)">
      <data key="d0">Researchers (Thoppilan et al., 2022)</data>
    </node>
    <node id="Codex">
      <data key="d0">Codex</data>
    </node>
    <node id="OpenAI Davinci Codex API">
      <data key="d0">OpenAI Davinci Codex API</data>
    </node>
    <node id="Researchers (Chen et al., 2021)">
      <data key="d0">Researchers (Chen et al., 2021)</data>
    </node>
    <node id="Evaluation datasets">
      <data key="d0">Evaluation datasets</data>
    </node>
    <node id="Codex 12B">
      <data key="d0">Codex 12B</data>
    </node>
    <node id="46.8B">
      <data key="d0">46.8B</data>
    </node>
    <node id="39B">
      <data key="d0">39B</data>
    </node>
    <node id="100B">
      <data key="d0">100B</data>
    </node>
    <node id="PaLM-Coder">
      <data key="d0">PaLM-Coder</data>
    </node>
    <node id="137B">
      <data key="d0">137B</data>
    </node>
    <node id="18B">
      <data key="d0">18B</data>
    </node>
    <node id="Davinci Codex training data">
      <data key="d0">Davinci Codex training data</data>
    </node>
    <node id="8.7B">
      <data key="d0">8.7B</data>
    </node>
    <node id="44.8B tokens">
      <data key="d0">44.8B tokens</data>
    </node>
    <node id="ExtraPythonData">
      <data key="d0">ExtraPythonData</data>
    </node>
    <node id="39B code tokens">
      <data key="d0">39B code tokens</data>
    </node>
    <node id="GitHub code">
      <data key="d0">GitHub code</data>
    </node>
    <node id="PaLM-Coder 540B">
      <data key="d0">PaLM-Coder 540B</data>
    </node>
    <node id="5.8B tokens from GitHub repositories">
      <data key="d0">5.8B tokens from GitHub repositories</data>
    </node>
    <node id="Pre-training and fine-tuning data">
      <data key="d0">Pre-training and fine-tuning data</data>
    </node>
    <node id="All tasks">
      <data key="d0">All tasks</data>
    </node>
    <node id="Code and natural language tasks">
      <data key="d0">Code and natural language tasks</data>
    </node>
    <node id="Python code">
      <data key="d0">Python code</data>
    </node>
    <node id="Chen">
      <data key="d0">Chen</data>
    </node>
    <node id="further ﬁnetuning on code">
      <data key="d0">further ﬁnetuning on code</data>
    </node>
    <node id="code and natural language tasks">
      <data key="d0">code and natural language tasks</data>
    </node>
    <node id="observation about larger models">
      <data key="d0">observation about larger models</data>
    </node>
    <node id="both">
      <data key="d0">both</data>
    </node>
    <node id="smaller models">
      <data key="d0">smaller models</data>
    </node>
    <node id="few-shot evaluations and previously-published results">
      <data key="d0">few-shot evaluations and previously-published results</data>
    </node>
    <node id="Codex models">
      <data key="d0">Codex models</data>
    </node>
    <node id="Davinci">
      <data key="d0">Davinci</data>
    </node>
    <node id="Table 12">
      <data key="d0">Table 12</data>
    </node>
    <node id="6.5B tokens">
      <data key="d0">6.5B tokens</data>
    </node>
    <node id="observation">
      <data key="d0">observation</data>
    </node>
    <node id="larger models">
      <data key="d0">larger models</data>
    </node>
    <node id="62B tokens">
      <data key="d0">62B tokens</data>
    </node>
    <node id="other programming languages and natural language data">
      <data key="d0">other programming languages and natural language data</data>
    </node>
    <node id="PaLM-Coder results">
      <data key="d0">PaLM-Coder results</data>
    </node>
    <node id="transfer">
      <data key="d0">transfer</data>
    </node>
    <node id="mixture of 60% Python code and 30% code across languages">
      <data key="d0">mixture of 60% Python code and 30% code across languages</data>
    </node>
    <node id="code web docs in training mixture">
      <data key="d0">code web docs in training mixture</data>
    </node>
    <node id="540B token count">
      <data key="d0">540B token count</data>
    </node>
    <node id="web docs">
      <data key="d0">web docs</data>
    </node>
    <node id="DeepFix">
      <data key="d0">DeepFix</data>
    </node>
    <node id="8b">
      <data key="d0">8b</data>
    </node>
    <node id="GSM8K-Python">
      <data key="d0">GSM8K-Python</data>
    </node>
    <node id="64b">
      <data key="d0">64b</data>
    </node>
    <node id="535b">
      <data key="d0">535b</data>
    </node>
    <node id="88.4% pass@100">
      <data key="d0">88.4% pass@100</data>
    </node>
    <node id="+12% absolute improvement">
      <data key="d0">+12% absolute improvement</data>
    </node>
    <node id="GSM8K-Python dataset">
      <data key="d0">GSM8K-Python dataset</data>
    </node>
    <node id="+5% absolute improvement">
      <data key="d0">+5% absolute improvement</data>
    </node>
    <node id="58.1 pass@1 score">
      <data key="d0">58.1 pass@1 score</data>
    </node>
    <node id="pass@1 score 57.5">
      <data key="d0">pass@1 score 57.5</data>
    </node>
    <node id="DeepFix problem">
      <data key="d0">DeepFix problem</data>
    </node>
    <node id="Figure 13">
      <data key="d0">Figure 13</data>
    </node>
    <node id="PaLM-Coder 540B model">
      <data key="d0">PaLM-Coder 540B model</data>
    </node>
    <node id="Figures 13 and 14">
      <data key="d0">Figures 13 and 14</data>
    </node>
    <node id="82.1%">
      <data key="d0">82.1%</data>
    </node>
    <node id="71.7%">
      <data key="d0">71.7%</data>
    </node>
    <node id="DeepFix problems">
      <data key="d0">DeepFix problems</data>
    </node>
    <node id="DeepFix code repair task">
      <data key="d0">DeepFix code repair task</data>
    </node>
    <node id="58 .1">
      <data key="d0">58 .1</data>
    </node>
    <node id="fixed C programs">
      <data key="d0">fixed C programs</data>
    </node>
    <node id="prior work (Yasunaga &amp; Liang, 2021)">
      <data key="d0">prior work (Yasunaga &amp; Liang, 2021)</data>
    </node>
    <node id="model">
      <data key="d0">model</data>
    </node>
    <node id="code formatter">
      <data key="d0">code formatter</data>
    </node>
    <node id="broken C programs">
      <data key="d0">broken C programs</data>
    </node>
    <node id="Davinci Codex">
      <data key="d0">Davinci Codex</data>
    </node>
    <node id="broken code">
      <data key="d0">broken code</data>
    </node>
    <node id="%">
      <data key="d0">%</data>
    </node>
    <node id="small normalized edit distances">
      <data key="d0">small normalized edit distances</data>
    </node>
    <node id="small edits">
      <data key="d0">small edits</data>
    </node>
    <node id="few lines changed">
      <data key="d0">few lines changed</data>
    </node>
    <node id="metrics">
      <data key="d0">metrics</data>
    </node>
    <node id="minor stylistic changes">
      <data key="d0">minor stylistic changes</data>
    </node>
    <node id="code fixes">
      <data key="d0">code fixes</data>
    </node>
    <node id="compile rate">
      <data key="d0">compile rate</data>
    </node>
    <node id="changed prompt">
      <data key="d0">changed prompt</data>
    </node>
    <node id="success rate for at most 5 lines changed">
      <data key="d0">success rate for at most 5 lines changed</data>
    </node>
    <node id="DeepFix dataset">
      <data key="d0">DeepFix dataset</data>
    </node>
    <node id="ground truth fixes or input-output examples">
      <data key="d0">ground truth fixes or input-output examples</data>
    </node>
    <node id="Table 13">
      <data key="d0">Table 13</data>
    </node>
    <node id="lines changed metrics">
      <data key="d0">lines changed metrics</data>
    </node>
    <node id="normalized edit distance metrics">
      <data key="d0">normalized edit distance metrics</data>
    </node>
    <node id="new prompts">
      <data key="d0">new prompts</data>
    </node>
    <node id="DeepFix success rates">
      <data key="d0">DeepFix success rates</data>
    </node>
    <node id="Normalized Edit Distance">
      <data key="d0">Normalized Edit Distance</data>
    </node>
    <node id="Dataset poisoning attacks">
      <data key="d0">Dataset poisoning attacks</data>
    </node>
    <node id="Code completion systems">
      <data key="d0">Code completion systems</data>
    </node>
    <node id="LMs">
      <data key="d0">LMs</data>
    </node>
    <node id="LevenshteinDistance">
      <data key="d0">LevenshteinDistance</data>
    </node>
    <node id="Lines Changed">
      <data key="d0">Lines Changed</data>
    </node>
    <node id="suggested code">
      <data key="d0">suggested code</data>
    </node>
    <node id="prompt">
      <data key="d0">prompt</data>
    </node>
    <node id="developers">
      <data key="d0">developers</data>
    </node>
    <node id="test suite">
      <data key="d0">test suite</data>
    </node>
    <node id="Schuster et al.">
      <data key="d0">Schuster et al.</data>
    </node>
    <node id="code completion systems">
      <data key="d0">code completion systems</data>
    </node>
    <node id="dataset poisoning attacks">
      <data key="d0">dataset poisoning attacks</data>
    </node>
    <node id="code suggestions">
      <data key="d0">code suggestions</data>
    </node>
    <node id="buggy code">
      <data key="d0">buggy code</data>
    </node>
    <node id="incorrect generated code">
      <data key="d0">incorrect generated code</data>
    </node>
    <node id="program repair literature">
      <data key="d0">program repair literature</data>
    </node>
    <node id="C programming course">
      <data key="d0">C programming course</data>
    </node>
    <node id="Qi et al.">
      <data key="d0">Qi et al.</data>
    </node>
    <node id="machine translation settings">
      <data key="d0">machine translation settings</data>
    </node>
    <node id="Pearce et al.">
      <data key="d0">Pearce et al.</data>
    </node>
    <node id="Allamanis et al.">
      <data key="d0">Allamanis et al.</data>
    </node>
    <node id="readability evaluation">
      <data key="d0">readability evaluation</data>
    </node>
    <node id="evaluation">
      <data key="d0">evaluation</data>
    </node>
    <node id="security evaluation">
      <data key="d0">security evaluation</data>
    </node>
    <node id="English">
      <data key="d0">English</data>
    </node>
    <node id="English-German">
      <data key="d0">English-German</data>
    </node>
    <node id="English-French">
      <data key="d0">English-French</data>
    </node>
    <node id="English-Romanian">
      <data key="d0">English-Romanian</data>
    </node>
    <node id="WMT">
      <data key="d0">WMT</data>
    </node>
    <node id="WMT'16 English-German">
      <data key="d0">WMT'16 English-German</data>
    </node>
    <node id="WMT'16 English-Romanian">
      <data key="d0">WMT'16 English-Romanian</data>
    </node>
    <node id="Kazakh">
      <data key="d0">Kazakh</data>
    </node>
    <node id="WMT'19 French-German">
      <data key="d0">WMT'19 French-German</data>
    </node>
    <node id="WMT'14 English-French">
      <data key="d0">WMT'14 English-French</data>
    </node>
    <node id="Prior SOTA PaLM 540B">
      <data key="d0">Prior SOTA PaLM 540B</data>
    </node>
    <node id="French">
      <data key="d0">French</data>
    </node>
    <node id="Finetuned SOTA en fr">
      <data key="d0">Finetuned SOTA en fr</data>
    </node>
    <node id="German">
      <data key="d0">German</data>
    </node>
    <node id="WMT'19 English-Kazakh">
      <data key="d0">WMT'19 English-Kazakh</data>
    </node>
    <node id="Zero-resource languages">
      <data key="d0">Zero-resource languages</data>
    </node>
    <node id="translation capabilities">
      <data key="d0">translation capabilities</data>
    </node>
    <node id="English-centric language pairs">
      <data key="d0">English-centric language pairs</data>
    </node>
    <node id="FLAN">
      <data key="d0">FLAN</data>
    </node>
    <node id="Table 14">
      <data key="d0">Table 14</data>
    </node>
    <node id="Supervised Models">
      <data key="d0">Supervised Models</data>
    </node>
    <node id="PaLM-540B Performance">
      <data key="d0">PaLM-540B Performance</data>
    </node>
    <node id="French-German Setting">
      <data key="d0">French-German Setting</data>
    </node>
    <node id="German-French Language Pair">
      <data key="d0">German-French Language Pair</data>
    </node>
    <node id="Kazakh-English Language Pair">
      <data key="d0">Kazakh-English Language Pair</data>
    </node>
    <node id="Multilingual translation">
      <data key="d0">Multilingual translation</data>
    </node>
    <node id="1 billion parameters">
      <data key="d0">1 billion parameters</data>
    </node>
    <node id="Large translation models">
      <data key="d0">Large translation models</data>
    </node>
    <node id="PaLM conﬁguration">
      <data key="d0">PaLM conﬁguration</data>
    </node>
    <node id="Specialists">
      <data key="d0">Specialists</data>
    </node>
    <node id="Generalists">
      <data key="d0">Generalists</data>
    </node>
    <node id="Specialized models">
      <data key="d0">Specialized models</data>
    </node>
    <node id="Downstream tasks">
      <data key="d0">Downstream tasks</data>
    </node>
    <node id="Resource-rich scenarios">
      <data key="d0">Resource-rich scenarios</data>
    </node>
    <node id="Generalist models">
      <data key="d0">Generalist models</data>
    </node>
    <node id="Training specialists or generalists">
      <data key="d0">Training specialists or generalists</data>
    </node>
    <node id="LaMDA 137B">
      <data key="d0">LaMDA 137B</data>
    </node>
    <node id="SOTA results">
      <data key="d0">SOTA results</data>
    </node>
    <node id="mT5">
      <data key="d0">mT5</data>
    </node>
    <node id="Megatron-Turing NLG">
      <data key="d0">Megatron-Turing NLG</data>
    </node>
    <node id="BART">
      <data key="d0">BART</data>
    </node>
    <node id="Generation Evaluation and Metrics benchmark (GEM)">
      <data key="d0">Generation Evaluation and Metrics benchmark (GEM)</data>
    </node>
    <node id="Xue et al. (2021b)">
      <data key="d0">Xue et al. (2021b)</data>
    </node>
    <node id="Gehrmann et al. (2021)">
      <data key="d0">Gehrmann et al. (2021)</data>
    </node>
    <node id="Lewis et al. (2020)">
      <data key="d0">Lewis et al. (2020)</data>
    </node>
    <node id="Raﬀel et al. (2020)">
      <data key="d0">Raﬀel et al. (2020)</data>
    </node>
    <node id="Clean E2E NLG">
      <data key="d0">Clean E2E NLG</data>
    </node>
    <node id="Czech">
      <data key="d0">Czech</data>
    </node>
    <node id="WikiLingua">
      <data key="d0">WikiLingua</data>
    </node>
    <node id="MLSum">
      <data key="d0">MLSum</data>
    </node>
    <node id="GEM benchmark">
      <data key="d0">GEM benchmark</data>
    </node>
    <node id="Russian">
      <data key="d0">Russian</data>
    </node>
    <node id="Vietnamese">
      <data key="d0">Vietnamese</data>
    </node>
    <node id="Spanish">
      <data key="d0">Spanish</data>
    </node>
    <node id="XSum">
      <data key="d0">XSum</data>
    </node>
    <node id="Czech Restaurant response generation">
      <data key="d0">Czech Restaurant response generation</data>
    </node>
    <node id="Turkish">
      <data key="d0">Turkish</data>
    </node>
    <node id="known weaknesses">
      <data key="d0">known weaknesses</data>
    </node>
    <node id="Duˇsek et al.">
      <data key="d0">Duˇsek et al.</data>
    </node>
    <node id="NLG tasks">
      <data key="d0">NLG tasks</data>
    </node>
    <node id="BLEURT-20">
      <data key="d0">BLEURT-20</data>
    </node>
    <node id="Novikova et al.">
      <data key="d0">Novikova et al.</data>
    </node>
    <node id="ROUGE-2">
      <data key="d0">ROUGE-2</data>
    </node>
    <node id="WebNLG 2020">
      <data key="d0">WebNLG 2020</data>
    </node>
    <node id="pretraining">
      <data key="d0">pretraining</data>
    </node>
    <node id="output">
      <data key="d0">output</data>
    </node>
    <node id="few-shot exemplars">
      <data key="d0">few-shot exemplars</data>
    </node>
    <node id="training context">
      <data key="d0">training context</data>
    </node>
    <node id="F-measure of ROUGE-2">
      <data key="d0">F-measure of ROUGE-2</data>
    </node>
    <node id="output prompt">
      <data key="d0">output prompt</data>
    </node>
    <node id="ROUGE">
      <data key="d0">ROUGE</data>
    </node>
    <node id="ROUGE-2, ROUGE-L (Lin, 2004), BLEURT-20 (Pu et al., 2021)">
      <data key="d0">ROUGE-2, ROUGE-L (Lin, 2004), BLEURT-20 (Pu et al., 2021)</data>
    </node>
    <node id="inputs and targets">
      <data key="d0">inputs and targets</data>
    </node>
    <node id="Appendix H.3">
      <data key="d0">Appendix H.3</data>
    </node>
    <node id="Gehrmann et al.">
      <data key="d0">Gehrmann et al.</data>
    </node>
    <node id="task-speciﬁc prompt">
      <data key="d0">task-speciﬁc prompt</data>
    </node>
    <node id="input">
      <data key="d0">input</data>
    </node>
    <node id="best model checkpoint for each dataset">
      <data key="d0">best model checkpoint for each dataset</data>
    </node>
    <node id="T5 XXL baselines">
      <data key="d0">T5 XXL baselines</data>
    </node>
    <node id="constant learning rate of 5 ×10−5">
      <data key="d0">constant learning rate of 5 ×10−5</data>
    </node>
    <node id="ROUGE-L">
      <data key="d0">ROUGE-L</data>
    </node>
    <node id="PaLM model checkpoint">
      <data key="d0">PaLM model checkpoint</data>
    </node>
    <node id="ROUGE-1">
      <data key="d0">ROUGE-1</data>
    </node>
    <node id="beam-search with a beam size of 4">
      <data key="d0">beam-search with a beam size of 4</data>
    </node>
    <node id="top-k sampling with k=10">
      <data key="d0">top-k sampling with k=10</data>
    </node>
    <node id="decoded">
      <data key="d0">decoded</data>
    </node>
    <node id="Results">
      <data key="d0">Results</data>
    </node>
    <node id="beam-search">
      <data key="d0">beam-search</data>
    </node>
    <node id="Table 16">
      <data key="d0">Table 16</data>
    </node>
    <node id="parameters">
      <data key="d0">parameters</data>
    </node>
    <edge source="Parker Barnes" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Emily Reif" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kensen Shi" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Paul Barham" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Jacob Devlin" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Aakanksha Chowdhery" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Vinodkumar Prabhakaran" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM: Scaling Language Modeling with Pathways" target="Training Instability">
      <data key="d1">HAS_PROBLEM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM: Scaling Language Modeling with Pathways" target="Gradient Clipping">
      <data key="d1">USED_METHOD</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM: Scaling Language Modeling with Pathways" target="Loss Spikes">
      <data key="d1">OBSERVED_RESULT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM: Scaling Language Modeling with Pathways" target="Restarting Training">
      <data key="d1">IMPLEMENTED_STRATEGY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Hyung Won Chung" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Jude Jenkins" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Nan Du" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Sasha Tsvyashchenko" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Charles Sutton" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Maarten Bosma" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Abhishek Rao" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Adam Roberts" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Reiner Pope" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Parker Schuh" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Sharan Narang" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Sharan Narang" target="google.com">
      <data key="d1">CORRESPONDENCE_AUTHOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Language Modeling">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="hundreds of language understanding and generation benchmarks">
      <data key="d1">PERFORMS_FEW_SHOT_LEARNING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BIG-bench benchmark">
      <data key="d1">ACHIEVES_BREAKTHROUGH_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="multi-step reasoning tasks">
      <data key="d1">OUTPERFORMS_FINETUNED_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="multilingual tasks and source code generation">
      <data key="d1">HAS_STRONG_CAPABILITIES_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="wide array of benchmarks">
      <data key="d1">PERFORMS_COMPETITIVELY_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="model scale">
      <data key="d1">STUDIES_TRAINING_DATA_MEMORIZATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="bias and toxicity">
      <data key="d1">PROVIDES_COMPREHENSIVE_ANALYSIS_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="researcher at Google">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="training dataset">
      <data key="d1">TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Training Dataset">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Training Infrastructure">
      <data key="d1">USED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Training Setup">
      <data key="d1">USED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Evaluation">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BIG-bench">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Code Tasks">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Multilingual Natural Language Generation">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Analysis">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Multilingual Question Answering">
      <data key="d1">RELATED_WORK</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Memorization">
      <data key="d1">MEMORIZED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Dataset Contamination">
      <data key="d1">FOUND_TO_CONTAMINATE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Representational Bias Analysis">
      <data key="d1">FOUND_TO_EXHIBIT_REPRESENTATIONAL_BIAS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Toxicity in open-ended generation">
      <data key="d1">FOUND_TO_PRODUCE_TOXIC_OUTPUT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Limitations">
      <data key="d1">FOUND_TO_HAVE_LIMITATIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Ethical Considerations">
      <data key="d1">REQUIRED_ETHICAL_CONSIDERATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Related Work">
      <data key="d1">RELATED_WORK</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Open Questions in Scaling">
      <data key="d1">OPEN_QUESTION_IN_SCALING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Conclusion">
      <data key="d1">CONCLUDED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BERT and T5">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="English NLP tasks on smaller models">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BIG-bench results">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BERT">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="T5">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Transformer architecture">
      <data key="d1">IS_A</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GPT-3">
      <data key="d1">SUCCEEDED_PREVIOUS_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Pathways">
      <data key="d1">USED_TOGETHER_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="780 billion tokens of high-quality text">
      <data key="d1">TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="540 billion">
      <data key="d1">HAS_PARAMETER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="780 billion tokens of text">
      <data key="d1">TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="state-of-the-art few-shot results">
      <data key="d1">ACHIEVES_RESULT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="hundreds of natural language tasks">
      <data key="d1">PERFORMS_WELL_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="breakthrough performance">
      <data key="d1">ACHIEVES_RESULT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="TPU v4 chips">
      <data key="d1">TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="hundreds of natural language, code, and mathematical reasoning tasks">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="TPU v4 Pods">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="46.2%">
      <data key="d1">ACHIEVED_HIGH_EFFICIENCY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Section 6">
      <data key="d1">ACHIEVED_STATE_OF_THE_ART_RESULTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="explanations using chain-of-thought prompting (Wei et al., 2022b)">
      <data key="d1">GENERATED_EXPLANATIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="large LMs">
      <data key="d1">IMPROVED_SCALING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GLaM, GPT-3, Megatron–Turing NLG, Gopher, Chinchilla, LaMDA">
      <data key="d1">OUTPERFORMED_OTHER_MODELS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GLaM">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Megatron–Turing NLG">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Gopher">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Chinchilla">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="LaMDA">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="8B">
      <data key="d1">SCALING_BEHAVIOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="62B">
      <data key="d1">SCALING_BEHAVIOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="540B">
      <data key="d1">SCALING_BEHAVIOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="few-shot evaluation">
      <data key="d1">PERFORMS_WELL_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="state of the art">
      <data key="d1">MATCHES_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="exploratory capabilities">
      <data key="d1">DEMONSTRATES_EXPLORATORY_CAPABILITIES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="discontinuous improvements">
      <data key="d1">EXHIBITS_DISCONTINUOUS_IMPROVEMENTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="prior state of the art in non-English summarization tasks">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="prior state of the art in translation tasks">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Transformer">
      <data key="d1">USES_ARCHITECTURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Winogender coreference task">
      <data key="d1">SET_A_NEW_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Muslims">
      <data key="d1">FALSLEY_AFFIRMS_STEREOTYPES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="terrorism, extremism, and violence">
      <data key="d1">FALSLEY_AFFIRMS_STEREOTYPES_ASSOCIATING_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="SwiGLU Activation">
      <data key="d1">USES_ACTIVATION_FUNCTION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Parallel Layers">
      <data key="d1">USES_LAYER_FORMULATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Transformer model architecture">
      <data key="d1">USES_TRANSFORMER_MODEL_ARCHITECTURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="training speed">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Ablation experiments">
      <data key="d1">EVALUATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="8B scale">
      <data key="d1">EVALUATED_AT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="62B scale">
      <data key="d1">EVALUATED_AT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="quality neutral effect of parallel layers">
      <data key="d1">PREDICTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="RoPE Embeddings">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Input-Output Embeddings">
      <data key="d1">SHARES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Biases">
      <data key="d1">DOES_NOT_USE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="32">
      <data key="d1">HAS_LAYER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="16">
      <data key="d1">HAS_PARAMETER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="8">
      <data key="d1">HAS_BATCH_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Social media conversations">
      <data key="d1">USES_DATA_SOURCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Filtered webpages">
      <data key="d1">USES_DATA_SOURCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Books">
      <data key="d1">USES_DATA_SOURCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GitHub (code)">
      <data key="d1">USES_DATA_SOURCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="JAX and T5X">
      <data key="d1">BASED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="TPU conﬁguration">
      <data key="d1">USED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="researchers">
      <data key="d1">SUPPORTED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="two TPU v4 pods">
      <data key="d1">SCALES_TRAINING_ACROSS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="standard within-pod data and model parallelism">
      <data key="d1">EXECUTES_FORWARD_AND_BACKWARD_COMPUTATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Scaling Language Modeling">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="DCN links">
      <data key="d1">IMPLEMENTED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Language Models">
      <data key="d1">TRAINING_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="1.95x">
      <data key="d1">ACHIEVES_THROUGHPUT_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Optimizations">
      <data key="d1">HAS_OPTIMIZATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="57.8%">
      <data key="d1">HAS_Hardware_FLOPs_utilization</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Megatron LM">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Narayanan et al. (2021b)">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Adam">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Adafactor">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="global norm gradient clipping">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="bitwise determinism">
      <data key="d1">HAS_FEATURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="large batch size schedule">
      <data key="d1">HAS_FEATURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="TPU">
      <data key="d1">INCREASES_EFFICIENCY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Bitwise determinism">
      <data key="d1">IS_REPRODUCIBLE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="JAX+XLA+T5X">
      <data key="d1">USES_METHOD</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Deterministic dataset pipeline">
      <data key="d1">HAS_PIPELINE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Dropout">
      <data key="d1">USES_METHOD</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Training Instability">
      <data key="d1">IS_STABLE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Smaller models">
      <data key="d1">IS_MORE_INSTABLE_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Du et al.">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Brown et al.">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Prior state-of-the-art results from other large language models">
      <data key="d1">IS_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Natural Questions">
      <data key="d1">IMPROVES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="TriviaQA">
      <data key="d1">IMPROVES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="SOTAPaLM 540B">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Prior SOTAPaLM 540B">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="TriviaQA (EM)">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Natural Questions (EM)">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Web Questions (EM)">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Lambada (EM)">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="HellaSwag">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="StoryCloze">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Winograd">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Winogrande">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="57.3a69.4">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="57.8a70.8">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="58.6a 70.8">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="81.5b77.6">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="84.0b79.9">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="85.0b 81.5">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="71.1a80.8">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="71.8a82.9">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="71.8a 83.3">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="64.7a75.5">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="66.5a78.7">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="67.0a 79.6">
      <data key="d1">ACHIEVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="41 .5">
      <data key="d1">ACHIEVED_SCORE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.">
      <data key="d1">WORKED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="57 .7">
      <data key="d1">ACHIEVED_SCORE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Table 5: Average (Avg) Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.">
      <data key="d1">WORKED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="MMLU benchmark">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="SuperGLUE benchmark">
      <data key="d1">FINETUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="less than 15K steps">
      <data key="d1">CONVERGED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="T5-11B">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="ST-MoE-32B">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="competitive close-to-SOTA performance">
      <data key="d1">OBTAINED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="humans">
      <data key="d1">OUTPERFORMS_HUMANS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="higher score than the average score of humans">
      <data key="d1">ACHIEVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Scaling Language Modeling with Pathways">
      <data key="d1">DESCRIPTION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="wikihow">
      <data key="d1">ACHIEVES_ACCURACY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="logical args">
      <data key="d1">ACHIEVES_ACCURACY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="PaLM 62B">
      <data key="d1">IMPROVES_UPON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="PaLM 8b">
      <data key="d1">IMPROVES_UPON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="human asked to solve the task">
      <data key="d1">HAS_DIFFICULTY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Human">
      <data key="d1">PERFORMS_BEYOND_AVERAGE_HUMAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Persian Idioms">
      <data key="d1">EXHIBITS_LANGUAGE_ABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Swedish to German Proverbs">
      <data key="d1">EXHIBITS_LANGUAGE_ABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Periodic Elements">
      <data key="d1">LEVERAGES_MEMORIZATION_CAPABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Common Morpheme">
      <data key="d1">EXHIBITS_NLP_CAPABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Sufficient Information">
      <data key="d1">EXHIBITS_NLP_CAPABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Logical Args">
      <data key="d1">EXHIBITS_NLP_CAPABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Cause and Effect Task">
      <data key="d1">DETERMINES_CAUSE_EFFECT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BIG-bench Lite">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="8B model">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="540B model">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="3 tasks">
      <data key="d1">PERFORMS_BEST_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="training data">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="reasoning tasks">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Chain-of-thought prompting">
      <data key="d1">IMPROVED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Nye et al. (2021)">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Cobbe et al. (2021)">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Wei et al. (2022b)">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="SOTA accuracy across a variety of arithmetic and commonsense reasoning tasks">
      <data key="d1">ACHIEVED_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="chain-of-thought prompting">
      <data key="d1">USED_CHAIN_OF_THOUGHT_PROMPTING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="arithmetic datasets GSM8K">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="common sense reasoning datasets">
      <data key="d1">USED_METHOD</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="CommonsenseQA">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="StrategyQA">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="58%">
      <data key="d1">ACHIEVED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Cobbe et al.">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="SVAMP">
      <data key="d1">ACHIEVES_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="ASDiv">
      <data key="d1">ACHIEVES_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="AQuA">
      <data key="d1">ACHIEVES_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Chain-of-Thought Prompting">
      <data key="d1">USES_TECHNIQUE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Model Scaling">
      <data key="d1">USES_TECHNIQUE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GSM8K">
      <data key="d1">ACHIEVES_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="MAWPS">
      <data key="d1">ACHIEVES_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="few-shot prompts">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="test set">
      <data key="d1">USED_TO_CREATE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="DeepFix (Gupta et al., 2017)">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="compiler errors">
      <data key="d1">USED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="1260 programs">
      <data key="d1">USED_TO_TEST</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Codex">
      <data key="d1">COMPARABLE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Researchers (Thoppilan et al., 2022)">
      <data key="d1">MEASURED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GitHub code">
      <data key="d1">INCLUDED_IN_TRAINING_DATA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Code and natural language tasks">
      <data key="d1">ACHIEVES_STATE_OF_THE_ART_PERFORMANCE_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="code and natural language tasks">
      <data key="d1">ACHIEVES_EXCELLENT_PERFORMANCE_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="both">
      <data key="d1">ACHIEVES_BEST_PUBLISHED_PERFORMANCE_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Python code">
      <data key="d1">WAS_TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Codex models">
      <data key="d1">WAS_TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="few-shot evaluations and previously-published results">
      <data key="d1">ACHIEVES_COMPARABLE_PERFORMANCE_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="smaller models">
      <data key="d1">IS_MORE_SAMPLE_EFFICIENT_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="code">
      <data key="d1">FINE_TUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="540B token count">
      <data key="d1">FINE_TUNED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="HumanEval">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="58 .1">
      <data key="d1">OBTAINED_SCORE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="small edits">
      <data key="d1">PRODUCES_EDITS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="DeepFix">
      <data key="d1">COMPILED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Schuster et al.">
      <data key="d1">ASSOCIATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Chen et al.">
      <data key="d1">ASSOCIATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="machine translation">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="evaluation">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="machine translation settings">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="English">
      <data key="d1">TRANSLATES_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="WMT">
      <data key="d1">USED_FOR_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="WMT'14 English-French">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="WMT'16 English-German">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="WMT'16 English-Romanian">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="WMT'19 French-German">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Kazakh">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="translation capabilities">
      <data key="d1">HAS_TRANSLATION_CAPABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="FLAN">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Table 14">
      <data key="d1">SCORED_HIGHEST_IN_TABLE_14</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Generalist models">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Specialized models">
      <data key="d1">COMPARABLE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Megatron-Turing NLG">
      <data key="d1">COMPARE_AGAINST</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Generation Evaluation and Metrics benchmark (GEM)">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="mT5">
      <data key="d1">USED_FOR_FINETUNING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="BART">
      <data key="d1">USED_FOR_FINETUNING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Gehrmann et al. (2021)">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="known weaknesses">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="GEM benchmark">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="MLSum">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="WikiLingua">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="XSum">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Clean E2E NLG">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="Czech Restaurant response generation">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="NLG tasks">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="few-shot exemplars">
      <data key="d1">USED_FOR_FEW_SHOT_INFERENCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="decoder-only architecture">
      <data key="d1">USED_FOR_FINETUNING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="constant learning rate of 5 ×10−5">
      <data key="d1">HAS_PARAMETER_SETTING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="best model checkpoint for each dataset">
      <data key="d1">SELECTED_MODEL_CHECKPOINT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="top-k sampling with k=10">
      <data key="d1">USED_FOR_INFERENCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="T5 XXL baselines">
      <data key="d1">FINE_TUNED_TOGETHER_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="beam-search with a beam size of 4">
      <data key="d1">DECODED_USING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="parameters">
      <data key="d1">PARAMETERIZED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM" target="beam-search">
      <data key="d1">DECODED_USING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Ben Hutchinson" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Joshua Maynez" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Noam Shazeer" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Yi Tay" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gaurav Mishra" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="James Bradbury" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Sebastian Gehrmann" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Xuezhi Wang" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Oleksandr Polozov" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Zongwei Zhou" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Jason Wei" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Rewon Child" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Jeﬀ Dean" target="Jason Wei">
      <data key="d1">COLLEAGUE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Noah Fiedel" target="Jason Wei">
      <data key="d1">ASSOCIATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Katherine Lee" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Mark Diaz" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Orhan Firat" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Erica Moreira" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Erica Moreira" target="Jason Wei">
      <data key="d1">COAUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Brennan Saeta" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Michele Catasta" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">AUTHORED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chowdhery" target="google.com">
      <data key="d1">CORRESPONDENCE_AUTHOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="chowdhery@google.com" target="sharannarang@google.com">
      <data key="d1">CORRESPONDS_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Moonshot Factory" target="researcher at Google">
      <data key="d1">AFFILIATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Alphabet" target="Google">
      <data key="d1">PARENT_COMPANY_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Google" target="researcher at Google">
      <data key="d1">EMPLOYS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Google" target="whale">
      <data key="d1">HIRED_ELOQUENT_WHALE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Training Infrastructure" target="Efficiency">
      <data key="d1">HAS_CHARACTERISTIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Evaluation" target="English NLP tasks">
      <data key="d1">HAS_CATEGORY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Evaluation" target="Reasoning">
      <data key="d1">HAS_CATEGORY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Evaluation" target="Translation">
      <data key="d1">HAS_CATEGORY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Evaluation" target="Multilingual Question Answering">
      <data key="d1">HAS_CATEGORY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Training Setup" target="Instability">
      <data key="d1">HAS_CHARACTERISTIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench" target="PaLM">
      <data key="d1">USED_IN_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench" target="PaLM model family">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench" target="over 150 tasks">
      <data key="d1">INCLUDES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench" target="PaLM family of models">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench" target="PaLM 540B">
      <data key="d1">NEEDS_IMPROVEMENT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Training Dataset" target="6">
      <data key="d1">HAS_VERSION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BERT and T5" target="PaLM">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Bert (Devlin et al., 2019)" target="Authors (Devlin et al.)">
      <data key="d1">PUBLISHED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5 (Raffel et al., 2020)" target="Authors (Raffel et al.)">
      <data key="d1">PUBLISHED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="PaLM">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="21.3%">
      <data key="d1">HAS_MFU_number</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="Natural Language Generation and Natural Language Understanding results across 29 benchmarks using 1-shot evaluation.">
      <data key="d1">WORKED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="MMLU benchmark">
      <data key="d1">ACHIEVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="https://github.com/google/BIG-bench">
      <data key="d1">EVALUATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="PaLM 540B+chain-of-thought+calculator">
      <data key="d1">OUTPERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="34%">
      <data key="d1">ACHIEVED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="HumanEval">
      <data key="d1">HAS_PERFORMANCE_OF_0_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="machine translation">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3" target="English-centric language pairs">
      <data key="d1">EVALUATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5" target="masked LM">
      <data key="d1">TRAINED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5" target="natural language tasks">
      <data key="d1">ADAPTED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5" target="SOTA results">
      <data key="d1">FINETUNED_TO_PERFORM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5" target="Raﬀel et al. (2020)">
      <data key="d1">PREVIOUS_SOTA_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BERT" target="masked LM">
      <data key="d1">TRAINED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BERT" target="natural language tasks">
      <data key="d1">ADAPTED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Few-shot evaluation" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron–Turing NLG" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron–Turing NLG" target="GPT-3">
      <data key="d1">SUCCEEDED_PREVIOUS_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GLaM" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GLaM" target="articles, source code, and social media conversations">
      <data key="d1">USED_TO_TRAIN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GLaM" target="TPU system">
      <data key="d1">USED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GLaM" target="58 .4">
      <data key="d1">ACHIEVED_SCORE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GLaM" target="MMLU benchmark">
      <data key="d1">ACHIEVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chinchilla" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chinchilla" target="GPT-3">
      <data key="d1">SUCCEEDED_PREVIOUS_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chinchilla" target="higher score than the average score of humans">
      <data key="d1">ACHIEVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chinchilla" target="PaLM 540B">
      <data key="d1">INCLUDED_IN_PRIOR_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chinchilla" target="Prior SOTA">
      <data key="d1">INCLUDES_IN_PRIOR_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="GPT-3">
      <data key="d1">SUCCEEDED_PREVIOUS_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="TPU v3 Pods">
      <data key="d1">USED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="four DCN-connected TPU v3 Pods">
      <data key="d1">TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="PaLM 540B">
      <data key="d1">USED_PIPELINE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="32.5%">
      <data key="d1">HAS_MFU_number</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher" target="Prior SOTA">
      <data key="d1">INCLUDES_IN_PRIOR_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="few-shot predictions" target="PaLM: Scaling Language Modeling with Pathways">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="GPT-3">
      <data key="d1">SUCCEEDED_PREVIOUS_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="articles, source code, and social media conversations">
      <data key="d1">USED_TO_TRAIN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="TPU system">
      <data key="d1">USED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="GitHub">
      <data key="d1">TRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="High (Austin et al., 2021)">
      <data key="d1">PROGRAM_SYNTHESIS_ABILITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="137B">
      <data key="d1">TRAINING_DATA_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="All tasks">
      <data key="d1">PERFORMS_ACROSS_ALL_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA" target="code web docs in training mixture">
      <data key="d1">DOES_NOT_SPECIFICALLY_OVERSAMPLE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="natural language task description" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="decoder-only architecture" target="few-shot predictions">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways" target="very large neural networks">
      <data key="d1">ENABLES_TRAINING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways" target="thousands of accelerator chips">
      <data key="d1">WORKS_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways" target="PaLM">
      <data key="d1">USED_TO_SCALE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways" target="pods">
      <data key="d1">USES_TWO_WAY_DATA_PARALLELISM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways" target="remote pod">
      <data key="d1">TRANSFERS_GRADIENTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways" target="next timestep">
      <data key="d1">APPLIES_PARAMETER_UPDATES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Barham et al." target="Pathways">
      <data key="d1">DESIGNED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TPU v4 chips" target="hosts">
      <data key="d1">ATTACHED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TPU v4 Pods" target="training infrastructure">
      <data key="d1">USED_FOR_TRAINING_INFRASTRUCTURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TPU team" target="Google">
      <data key="d1">COMMUNICATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Zeng et al." target="Chinese language">
      <data key="d1">ACHIEVED_STRONG_RESULTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Seattle, Washington" target="Pacific Ocean">
      <data key="d1">LOCATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Shelley" target="Seattle, Washington">
      <data key="d1">VISITS_CITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Shelley" target="Virginia">
      <data key="d1">FROM_CITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Shelley" target="Pacific Ocean">
      <data key="d1">LOCATED_NEAR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Shelley" target="Seattle">
      <data key="d1">WILL_VISIT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 4" target="new few-shot state of the art on 28 out of the 29 most widely evaluated English language understanding benchmarks">
      <data key="d1">PRESENTED_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="explanations using chain-of-thought prompting (Wei et al., 2022b)">
      <data key="d1">GENERATED_EXPLANATIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="1-shot and few-shot settings">
      <data key="d1">SETS_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="gender and occupation bias on the Winogender coreference task">
      <data key="d1">IMPROVES_ACCURACY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Winogender coreference task">
      <data key="d1">SETS_STATE_OF_THE_ART</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="PaLM 8B and PaLM 62B">
      <data key="d1">IS_IDENTICAL_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="118">
      <data key="d1">HAS_MODEL_LAYER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="PaLM">
      <data key="d1">IS_INSTANCE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="6144 chips">
      <data key="d1">SCALED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="each weight tensor partitioned over 3072 chips using 12-way model parallelism and 256-way fully sharded data parallelism">
      <data key="d1">SCALED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="256-way fully sharded data parallelism">
      <data key="d1">USED_DATA_PARALLELISM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Pathways system">
      <data key="d1">USED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="TPU v4 Pod">
      <data key="d1">USED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="12-way model parallelism and 256-way fully sharded data parallelism">
      <data key="d1">PARALLELIZED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Rematerialization">
      <data key="d1">USES_REMATRIALIZATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="High Accelerator Utilization">
      <data key="d1">ACHIEVES_HIGH_ACCELERATOR_UTILIZATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="XLA TPU Compiler Optimizations">
      <data key="d1">TRAIN_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Parallel Layers">
      <data key="d1">TRAIN_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="45.7%">
      <data key="d1">REPORTS_MFU</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="46.2%">
      <data key="d1">REPORTS_MFU</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="57.8%">
      <data key="d1">REPORTS_FLOPS_UTILIZATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Other large language models">
      <data key="d1">HAS_HIGHER_RESULTS_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Prior SOTA results">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Reading Comprehension and NLI tasks">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Megatron-Turing NLG 530B">
      <data key="d1">IS_BIGGER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Natural Language Generation (NLG)">
      <data key="d1">IMPROVES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Chinchilla model">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="prior SOTA">
      <data key="d1">OUTPERFORMS_PRIOR_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Prior SOTA">
      <data key="d1">PREDICTED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="logical sequence task">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="average human performance">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="90%">
      <data key="d1">ACHIEVES_ACCURACY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="twosentence version of the task">
      <data key="d1">CAN_SOLVE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Best human performance score">
      <data key="d1">ACHIEVES_HIGHER_PERFORMANCE_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="All model scales">
      <data key="d1">PERFORMS_BEST_AMONG_ALL_MODEL_SCALES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="58%">
      <data key="d1">ACHIEVED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Cobbe et al.">
      <data key="d1">OUTPERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="PaLM 540B w/o chain-of-thought">
      <data key="d1">OUTPERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="8-shot chain-of-thought prompting">
      <data key="d1">USES_PROMPTING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="55%">
      <data key="d1">ACHIEVED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="PaLM 62B">
      <data key="d1">FIXES_ERRORS_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="39B code tokens">
      <data key="d1">PRETRAINED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="web docs">
      <data key="d1">TRAINING_DATA_SOURCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B" target="Codex">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Section 9" target="2-shot exemplars">
      <data key="d1">SHOWED_EXEMPLARS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Section 6.3" target="PaLM">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kaplan et al." target="power law rule of thumb">
      <data key="d1">RELATED_WORK</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kaplan et al." target="observation about larger models">
      <data key="d1">MENTIONED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench collaboration" target="150+ new language understanding and generation tasks">
      <data key="d1">RELEASED_SUITE_OF_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench collaboration" target="BIG-bench">
      <data key="d1">CREATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="discontinuous improvements" target="PaLM">
      <data key="d1">OBSERVED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Section 6.7" target="question answering">
      <data key="d1">EVALUATES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Section 6.6" target="summarization">
      <data key="d1">EVALUATES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Section 6.2" target="BIG-bench">
      <data key="d1">REFERENCES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Section 6.5" target="machine translation">
      <data key="d1">EVALUATES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Muslims" target="terrorism, extremism, and violence">
      <data key="d1">ASSOCIATED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="8B parameters">
      <data key="d1">HAS_PARAMETER_COUNT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="PaLM 62B and PaLM 540B">
      <data key="d1">IS_IDENTICAL_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="32">
      <data key="d1">HAS_MODEL_LAYER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="PaLM">
      <data key="d1">IS_INSTANCE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="MMLU benchmark">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="Chinchilla model">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="80%">
      <data key="d1">HAS_ACCURACY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8B" target="twosentence version of the task">
      <data key="d1">PERFORMS_POORLY_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="overall toxicity level">
      <data key="d1">HAS_HIGHER_TOXICITY_LEVEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="PaLM 8B">
      <data key="d1">COMPARED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="PaLM 8B and PaLM 540B">
      <data key="d1">IS_IDENTICAL_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="64">
      <data key="d1">HAS_MODEL_LAYER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="PaLM">
      <data key="d1">IS_INSTANCE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="Natural Language Understanding (NLU)">
      <data key="d1">IMPROVES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="GPT-3 175B">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="Chinchilla model">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="english proverbs">
      <data key="d1">REQUIRES_ABSTRACT_REASONING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="PaLM 8b">
      <data key="d1">IMPROVES_UPON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="PaLM 540B">
      <data key="d1">IMPROVED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="PaLM 540B+chain-of-thought+calculator">
      <data key="d1">OUTPERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="33%">
      <data key="d1">ACHIEVED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="20 errors of semantic understanding">
      <data key="d1">MADE_ERRORS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B" target="GSM8K">
      <data key="d1">MAKES_REASONING_ERRORS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Vaswani et al." target="PaLM">
      <data key="d1">USED_IN_PA LM_MODEL_ARCHITECTURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="SwiGLU Activation" target="standard ReLU variant">
      <data key="d1">DEMONSTRATED_IMPROVEMENT_IN_QUALITY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Parallel Layers" target="15% faster training speed">
      <data key="d1">RESULTED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Multi-Query Attention" target="Transformer formulation">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="RoPE Embeddings" target="Absolute Position Embeddings">
      <data key="d1">HAS_BETTER_PERFORMANCE_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="SentencePiece" target="PaLM">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="vocabulary" target="lossless and reversible">
      <data key="d1">HAS_PROPERTY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="numbers" target="individual digit tokens">
      <data key="d1">ARE_SPLIT_INTO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="whitespace" target="vocabulary">
      <data key="d1">IS_PRESERVED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="out-of-vocabulary Unicode characters" target="UTF-8 bytes">
      <data key="d1">ARE_SPLIT_INTO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 1" target="Model architecture details for PaLM models.">
      <data key="d1">DEPICTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM pretraining dataset" target="LaMDA (Thoppilan et al., 2022) and GLaM (Du et al., 2021)">
      <data key="d1">IS_BASED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM pretraining dataset" target="780 billion tokens.">
      <data key="d1">CONTAINS_TOKENS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM Model Card" target="Mitchell et al. (2019)">
      <data key="d1">IS_INSTANCE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM Model Card" target="model’s architecture, training setup, training data, and intended usage.">
      <data key="d1">PROVIDES_INFORMATION_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="code" target="pretraining dataset">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="webpages" target="training set">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GitHub" target="source code">
      <data key="d1">HOSTED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="programming languages" target="Java, HTML, Javascript, Python, PHP, C#, XML">
      <data key="d1">INCLUDED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="webpage collections" target="high-quality webpage collections">
      <data key="d1">SIMILAR_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="articles" target="source code and social media conversations">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GitHub (code)" target="training dataset">
      <data key="d1">INCLUDED_IN_TRAINING_DATASET</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Du et al." target="PaLM dataset mixture creation">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Du et al." target="GLaM (Du et al., 2021) were each trained on a single TPU system without leveraging either pipeline parallelism or DCN.">
      <data key="d1">AUTHOR_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Books" target="training dataset">
      <data key="d1">INCLUDED_IN_TRAINING_DATASET</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Filtered webpages" target="multilingual corpus">
      <data key="d1">INCLUDED_IN_MULTILINGUAL_CORPUS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Lopes et al. (2017)" target="duplicate file removal in source code repositories">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Social media conversations" target="multilingual corpus">
      <data key="d1">INCLUDED_IN_MULTILINGUAL_CORPUS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Allamanis (2019)" target="duplicate file removal in source code repositories">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gebru et al." target="datasheet (Appendix D)">
      <data key="d1">CREATED_DATASHEET</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="News" target="training dataset">
      <data key="d1">INCLUDED_IN_TRAINING_DATASET</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Wikipedia" target="training dataset">
      <data key="d1">INCLUDED_IN_TRAINING_DATASET</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5X" target="model infrastructure">
      <data key="d1">USED_FOR_MODEL_INFRASTRUCTURE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron-Turing NLG 530B" target="A100 GPUs">
      <data key="d1">USED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron-Turing NLG 530B" target="Smith et al.">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Xu et al." target="Pods connected over data center network (DCN) using a combination of model and data parallelism">
      <data key="d1">AUTHOR_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Huang et al." target="This system, the largest TPU conﬁguration described to date, allowed us to eﬃciently scale training to 6144 chips without needing to use any pipeline parallelism">
      <data key="d1">AUTHOR_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Rae et al." target="Gopher (Rae et al., 2021) was trained on four DCN-connected TPU v3 Pods">
      <data key="d1">AUTHOR_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Thoppilan et al." target="LaMDA (Thoppilan et al., 2022) and GLaM (Du et al., 2021) were each trained on a single TPU system without leveraging either pipeline parallelism or DCN.">
      <data key="d1">AUTHOR_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Thoppilan et al." target="LaMDA 137B parameter model">
      <data key="d1">PUBLISHED_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Smith et al." target="Megatron-Turing NLG 530B (Smith et al., 2022) was trained on 2240 A100 GPUs using a combination of model, data, and pipeline parallelism,">
      <data key="d1">AUTHOR_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Smith et al." target="Megatron–Turing NLG 530B model">
      <data key="d1">REPORTED_TRAINING_throughput</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Smith et al." target="PaLM 540B">
      <data key="d1">USED_FOR_MFU_COMPUTATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Smith et al." target="2018">
      <data key="d1">PUBLISHED_RESEARCH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TPU v3 Chips" target="four DCN-connected TPU v3 Pods">
      <data key="d1">PART_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways system" target="Barham et al.">
      <data key="d1">IMPLEMENTED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TPU v4 pods" target="fast private interconnects">
      <data key="d1">CONNECTED_BY_FAST_PRIVATE_INTERCONNECTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Scheduler (per Pod)" target="TPU chips">
      <data key="d1">EXECUTES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Host (many per Pod)" target="TPU chips">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Model Components" target="Pod 2">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Component B" target="Pod 2">
      <data key="d1">EXECUTES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Component A" target="Pod 1">
      <data key="d1">EXECUTES_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TPU chips" target="fast private interconnects">
      <data key="d1">CONNECTED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Optimizer update" target="component B for optimizer update">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="cross-pod gradient transfer" target="corresponding hosts on the two pods">
      <data key="d1">REQUIRES_TRANSFER BETWEEN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="cross-pod gradient transfer" target="1:1 transfer between corresponding hosts on two pods">
      <data key="d1">REQUIRES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Transfer subgraph" target="cross-pod gradient transfer">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pod 1" target="Datacenter Network">
      <data key="d1">PART_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways program" target="component A">
      <data key="d1">EXECUTES_COMPONENT_A</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways program" target="other pod">
      <data key="d1">TRANSFERS_OUTPUT_GRADIENTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways program" target="component B">
      <data key="d1">EXECUTES_COMPONENT_B</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="data transfers" target="sharded-data flow execution model">
      <data key="d1">MANAGED_VIA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="hosts between the two pods" target="Google datacenter network">
      <data key="d1">CONNECTED_VIA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="hosts" target="two pods">
      <data key="d1">ACROSS_TWO_PODS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="hosts" target="Google datacenter network">
      <data key="d1">CONNECTED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="hosts" target="81 Tbps across all hosts">
      <data key="d1">AMOUNT_OF_DATA_TRANSFERRED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="JAX/XLA work" target="remote servers">
      <data key="d1">DISPATCHED_VIA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="model-sharded parameters" target="remote gradients">
      <data key="d1">NEEDS_REMOTE_GRADIENTS FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Google datacenter network" target="hosts">
      <data key="d1">CONNECTED_VIA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pathways networking stack" target="optimal DCN link utilization">
      <data key="d1">DESIGNED_TO_ENABLE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="hosts between two pods" target="gradient transfers">
      <data key="d1">EXCHANGING_DATA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="each pair of hosts" target="approximately 1.3 GB of gradients">
      <data key="d1">EXCHANGES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DCN links" target="Optimizations">
      <data key="d1">USES_PATHWAY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DCN links" target="stack">
      <data key="d1">ENABLES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DCN links" target="Gradient Transfers">
      <data key="d1">REDUCES_GRADIENT_TRANSFER_TIME</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Language Models" target="multi-step reasoning">
      <data key="d1">STRUGGLE_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Hardware FLOPs utilization" target="system-dependent and implementation-dependent design choices in the compiler can result in different number of operations">
      <data key="d1">HAS_ISSUE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="FLOPs utilization (HFU)" target="the ratio of FLOPs observed on a given device to its theoretical peak FLOPs">
      <data key="d1">REFLECTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Backwards pass of most neural network architectures using gradient descent" target="many intermediate activations for the batch must be stored in memory">
      <data key="d1">NEEDS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Hardware FLOPs" target="some forward pass operations can be re-computed (enabling some activations to be rematerialized rather than stored)">
      <data key="d1">USED_TO_SAVE_MEMORY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Training system" target="achieve a high throughput in tokens per second">
      <data key="d1">GOAL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Methodology used to count or track hardware FLOPs" target="observed hardware FLOPs">
      <data key="d1">DEPENDENT_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="FLOPs" target="FLOPs utilization (HFU)">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="FLOPs" target="memory">
      <data key="d1">IS_RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Rematerialization" target="memory usage with compute">
      <data key="d1">USED_TO_TRADE_OFF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="analytical accounting" target="Observed hardware FLOPs">
      <data key="d1">USED_TO_COUNT_FLOPS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="forward+backward passes" target="theoretical maximum throughput">
      <data key="d1">REQUIRED_TO_COMPUTE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="tokens per second" target="FLOPs">
      <data key="d1">GOAL_OF_TRAINING_SYSTEM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="hardware performance counters" target="Observed hardware FLOPs">
      <data key="d1">USED_TO_COUNT_FLOPs</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="MFU" target="system efficiency">
      <data key="d1">IS_IMPLEMENTATION_INDEPENDENT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="MFU" target="comparing models and systems">
      <data key="d1">IS_USEFUL_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="MFU" target="training throughput and model quality">
      <data key="d1">IS_CONTEXTUALIZED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="HFU" target="LLM training efficiency">
      <data key="d1">IS_NOT_MEANINGFUL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Patterson et al." target="OpenAI">
      <data key="d1">REPORTED_MFU_NUMBER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3 model" target="21.3%">
      <data key="d1">HAS_MFU_number</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="OpenAI" target="Patterson et al.">
      <data key="d1">REPORTED_MFU_NUMBER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="OpenAI" target="GSM8K math dataset">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B model" target="prior large models">
      <data key="d1">IS_CONTEXTUALIZED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B model" target="45.7%">
      <data key="d1">HAS_MFU_number</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B model" target="238.3K tokens/sec">
      <data key="d1">ACHIEVES_TRAINING_throughput</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B model" target="higher feasible batch size">
      <data key="d1">USES_REMATERIALIZATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B model" target="GPT-3 and Gopher models">
      <data key="d1">IS_CONTEXTUALIZED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gopher model" target="32.5%">
      <data key="d1">ACHIEVES_MFU_number</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron–Turing NLG 530B model" target="29.7%">
      <data key="d1">HAS_MFU_number</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron–Turing NLG 530B model" target="65.43K tokens/sec">
      <data key="d1">HAS_TRAINING_throughput</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Megatron LM" target="Earlier Benchmark Numbers">
      <data key="d1">REPORTED_MFU_BENCHMARK_NUMBERS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="3Gopher" target="0.0152 steps per second">
      <data key="d1">HAS_TRAINING_SPEED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Narayanan et al." target="2021b">
      <data key="d1">PUBLISHED_PAPER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Input embeddings" target="'N(0,1)'">
      <data key="d1">INITIALIZED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Model training" target="'standard setup for large Transformer language models'">
      <data key="d1">FOLLOWED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kernel weights" target="'fan-in variance scaling'">
      <data key="d1">INITIALIZED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Weight initialization" target="PaLM">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pre-softmax output logits" target="1 /√n">
      <data key="d1">SCALED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Adafactor" target="10−2">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Adafactor" target="10−2for the ﬁrst 10,000 steps">
      <data key="d1">HAS_HYPERPARAMETER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="global norm gradient clipping" target="Pascanu et al.">
      <data key="d1">DEFINED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="global norm gradient clipping" target="value of 1.0">
      <data key="d1">HAS_PARAMETER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="global norm gradient clipping" target="all models">
      <data key="d1">HAS_PARAMETER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pascanu et al." target="global norm gradient clipping">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Brown et al." target="PaLM">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Adam" target="β1= 0.9">
      <data key="d1">HAS_HYPERPARAMETER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="label smoothing" target="standard language modeling loss function">
      <data key="d1">USED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="large language models" target="global norm gradient clipping">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="rare embedding tokens" target="poorly estimated second moments">
      <data key="d1">HAS_CHARACTERISTIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="batch size" target="all models">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="batch size" target="the largest model">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="batch size" target="step 50k">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="batch size" target="step 115k">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="the model" target="standard language modeling loss function">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="average log probability" target="standard language modeling loss function">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="standard language modeling loss function" target="the model">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="tokens" target="average log probability">
      <data key="d1">HAS_PROPERTY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="tokens" target="all tokens">
      <data key="d1">HAS_PROPERTY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="tokens" target="label smoothing">
      <data key="d1">HAS_PROPERTY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="lr" target="dynamic weight decay">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="sequences" target="padding tokens">
      <data key="d1">HAS_PROPERTY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="sequence length" target="all models">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="McCandlish et al." target="2018">
      <data key="d1">PUBLISHED_RESEARCH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Training Instability" target="Bad Data">
      <data key="d1">CAUSE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Open-Domain Closed-Book Question Answering tasks" target="PaLM 540B">
      <data key="d1">IS_CHALLENGED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TriviaQA (Joshi et al., 2017)" target="PaLM 540B">
      <data key="d1">USED_IN_EVALUATION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Natural Questions (Kwiatkowski et al., 2019)" target="PaLM 540B">
      <data key="d1">USED_IN_EVALUATION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Web Questions (Berant et al., 2013)" target="PaLM 540B">
      <data key="d1">USED_IN_EVALUATION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Prior SOTA results" target="PaLM 540B">
      <data key="d1">IS_BEATEN_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3 175B" target="Brown et al.">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3 175B" target="PaLM 540B">
      <data key="d1">INCLUDED_IN_PRIOR_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GPT-3 175B" target="Prior SOTA">
      <data key="d1">INCLUDES_IN_PRIOR_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Prior SOTAPaLM 540B" target="PaLM 540B">
      <data key="d1">IS_VERSION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GLaM 62B/64E" target="Du et al.">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="RACE-h" target="GLaM 62B/64E">
      <data key="d1">COMPARE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="RACE-h" target="GPT-3 175B">
      <data key="d1">COMPARE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="RACE-h" target="Megatron-Turing NLG 530B">
      <data key="d1">COMPARE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="RACE-h" target="PaLM 540B">
      <data key="d1">COMPARE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="RACE-m/h" target="GPT-3 and other large LMs">
      <data key="d1">COMPARABLE_SCORE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ST-MoE-32B" target="PaLM model">
      <data key="d1">COMPARED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ST-MoE-32B" target="PaLM">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM model" target="coding tasks">
      <data key="d1">PERFORMED_WELL_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM model" target="GSM8K-Python task">
      <data key="d1">ACHIEVED_GOOD_RESULTS_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM model" target="LaMDA 137B parameter model">
      <data key="d1">COMPARISON_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM model" target="MBPP">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5-11B" target="PaLM model">
      <data key="d1">COMPARED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="T5-11B" target="PaLM">
      <data key="d1">COMPETES_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="few-shot results" target="finetuned results">
      <data key="d1">HAD_A_SIGNIFICANT_GAP</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="encoder-decoder models" target="autoregressive decoder-only models">
      <data key="d1">GENERALLY_OUTPERFORMED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B (finetuned)" target="State-of-the-art span corruption based Encoder-Decoder">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM model family" target="BIG-bench">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B" target="PaLM">
      <data key="d1">IMPROVED_VERSION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B" target="Best Decoder-only LM">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B" target="Supervised Models">
      <data key="d1">PERFORMS_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B" target="French-German Setting">
      <data key="d1">MATCHES_SUPERVISED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B" target="German-French Language Pair">
      <data key="d1">PROVIDES_STRONG_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-540B" target="Kazakh-English Language Pair">
      <data key="d1">PROVIDES_STRONG_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="gold labels" target="each task">
      <data key="d1">PROVIDED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="crowdsourcing platform" target="workers (typically 10)">
      <data key="d1">USED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="human performance metrics" target="BIG-bench data release">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B 5-shot" target="prior SOTA">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM models" target="performance as a function of scale">
      <data key="d1">FOLLOW_LOG_LINEAR_BEHAVIOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="goal step wikihow" target="events">
      <data key="d1">REQUIRES_REASONING_ABOUT_GOAL_STEP_RELATIONSHIP</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="logical args" target="passage">
      <data key="d1">REQUIRES_LOGICAL_INFERENCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="months" target="drink water, feel thirsty, seal water bottle, open water bottle">
      <data key="d1">LOGICAL_SEQUENCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="months" target="feel thirsty, open water bottle, drink water, seal water bottle">
      <data key="d1">LOGICAL_SEQUENCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="center" target="Vanessa">
      <data key="d1">OFFERED_NEW_JOB</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Vanessa" target="local center for homeless aid">
      <data key="d1">HELPED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Vanessa" target="job">
      <data key="d1">LOST_JOB</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Vanessa" target="location">
      <data key="d1">NAVIGATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="drink water" target="open water bottle">
      <data key="d1">PERFORMED_WHEN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="mathematical induction" target="logical inference rules">
      <data key="d1">USED_TO_INFER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="water bottle" target="drink water">
      <data key="d1">DRINK_FROM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="water bottle" target="seal water bottle">
      <data key="d1">CLOSED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="bottle" target="open water bottle">
      <data key="d1">FILLED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="seal water bottle" target="drink water">
      <data key="d1">AFTER_PERFORMING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="navigate" target="figure out where you would end up">
      <data key="d1">PERFORMED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="feel thirsty" target="open water bottle">
      <data key="d1">PERFORMED_WHEN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="english proverbs" target="high level of abstract reasoning capability">
      <data key="d1">REQUIRES_ABSTRACT_REASONING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 8b" target="logical sequence task">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62b" target="logical sequence task">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62b" target="log-linear projection using 8b →62b">
      <data key="d1">PREDICTED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="log-linear improvements" target="PaLM">
      <data key="d1">OBSERVED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BENCHMARK_DATA" target="TRAINING_CORPORA">
      <data key="d1">SHOULD_NEVER_APPEAR_IN_TRAINING_CORPORA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Figure 5" target="PaLM">
      <data key="d1">SHOWS_5-SHOT_EVALUATIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="relatively flat improvements" target="PaLM">
      <data key="d1">OBSERVED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Persian Idioms" target="PaLM 540B">
      <data key="d1">IS_PERFORMED_ACROSS_MANY_LANGUAGES_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Swedish to German Proverbs" target="PaLM 540B">
      <data key="d1">IS_PERFORMED_ACROSS_MANY_LANGUAGES_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="I washed the car because my car got dirty." target="cause andeﬀect (one sentence noprompt)">
      <data key="d1">EXAMPLE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="My car got dirty because I washed the car." target="cause andeﬀect (one sentence noprompt)">
      <data key="d1">EXAMPLE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="cause andeﬀect (two sentence)" target="cause andeﬀect">
      <data key="d1">IS_VERSION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Figure 6" target="PaLM 540b">
      <data key="d1">REFERENCES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Human (Avg.)" target="PaLM 540b">
      <data key="d1">OUTPERFORMS_ON_TASK</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540b" target="Human (Avg.)">
      <data key="d1">OUTPERFORMS_ON_TASK</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="cause andeﬀect (one sentence noprompt)" target="cause andeﬀect">
      <data key="d1">IS_VERSION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Tasks" target="PaLM 540b">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t1: auto debugging">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t2: bbq litejson">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t3: code linedescription">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t4: conceptual combinations">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t5: conlang translation">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t6: emoji movie">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t7: formal fallacies syllogisms negation">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t8: hindu knowledge">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t9: known unknowns">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t10: language identiﬀcation">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t11: logic gridpuzzle">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t12: logical deduction">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t13: misconceptions russian">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t14: novel concepts">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t15: operators">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t16: parsinlu reading comprehension">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t17: play dialog same ordiﬀerent">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BIG-bench Lite" target="t18: repeat copy logic">
      <data key="d1">HAS_TASKS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Task t24" target="Both PaLM 540B and human performance scores">
      <data key="d1">DIFICULT_FOR_BOTH_MODEL_AND_HUMANS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gold Labels" target="None">
      <data key="d1">LEAKED_INFORMATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Arithmetic Reasoning" target="None">
      <data key="d1">REQUIRES_MULTI_STEP_LOGICAL_INFERENCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Rae Et Al" target="2021">
      <data key="d1">PUBLISHED_PAPER</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Natural Language Math Problems" target="None">
      <data key="d1">INVOLVES_GRADE_SCHOOL_LEVEL_MATH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Model" target="PaLM">
      <data key="d1">SHOWED_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Roger" target="11 tennis balls">
      <data key="d1">HAS_TENNIS_BALLS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Roger" target="5 tennis balls">
      <data key="d1">OWNS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Roger" target="2 cans of tennis balls">
      <data key="d1">BOUGHT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Roger" target="3 tennis balls per can">
      <data key="d1">HAS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Roger" target="11">
      <data key="d1">HAS_TENNIS_BALLS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Roger" target="5">
      <data key="d1">HAS_TENNIS_BALLS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Sean" target="home">
      <data key="d1">WAS_IN_A_RUSH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Sean" target="slow down">
      <data key="d1">FORCED_TO_DO_SOMETHING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="post-hoc external calculator">
      <data key="d1">AUGMENTED_MODEL_PREDICTIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="external calculator">
      <data key="d1">USED_METHOD</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="model predictions">
      <data key="d1">AUGMENTED_MODEL_PREDICTIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="55%">
      <data key="d1">PUBLISHED_RESULT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="intermediate reasoning steps">
      <data key="d1">USED_INTERMEDIATE_REASONING_STEPS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="GSM8K">
      <data key="d1">PREVIOUS_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Cobbe et al." target="GSM8K dataset">
      <data key="d1">CREATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="CommonsenseQA" target="accuracy">
      <data key="d1">CLOSE_TO_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B w/o chain-of-thought" target="PaLM 540B+chain-of-thought">
      <data key="d1">OUTPERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="StrategyQA" target="accuracy">
      <data key="d1">ACHIEVED_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B+chain-of-thought" target="PaLM 62B">
      <data key="d1">SCORED_HIGHER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B+chain-of-thought" target="accuracy">
      <data key="d1">ACHIEVED_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 62B+chain-of-thought" target="PaLM 540B+chain-of-thought">
      <data key="d1">OUTPERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 540B+chain-of-thought+calculator" target="scaling up to the 540B model size">
      <data key="d1">CORRECTED_ERRORS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM 64B" target="GSM8K">
      <data key="d1">MAKES_REASONING_ERRORS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GSM8K" target="PaLM results">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="AQuA" target="accuracy">
      <data key="d1">CLOSE_TO_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="SVAMP" target="accuracy">
      <data key="d1">ACHIEVED_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="MAWPS" target="accuracy">
      <data key="d1">ACHIEVED_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ASDiv" target="accuracy">
      <data key="d1">CLOSE_TO_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Lan et al." target="MAWPS">
      <data key="d1">PREVIOUS_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Talmor et al." target="CommonsenseQA">
      <data key="d1">PREVIOUS_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Piekos et al." target="AQuA">
      <data key="d1">PREVIOUS_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pi et al." target="SVAMP">
      <data key="d1">PREVIOUS_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Geva et al." target="StrategyQA">
      <data key="d1">PREVIOUS_SOTA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Li et al." target="competitive programming">
      <data key="d1">RESEARCHED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chen et al." target="code completion">
      <data key="d1">RESEARCHED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chen et al." target="HumanEval dataset">
      <data key="d1">CREATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chen et al." target="pass@ kestimator">
      <data key="d1">PROPOSED_METRIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chen et al." target="Codex models">
      <data key="d1">REPORTED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chen et al." target="PaLM-Coder">
      <data key="d1">PERFORMED_FINE_TUNING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Austin et al." target="program synthesis from natural language specifications">
      <data key="d1">RESEARCHED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Austin et al." target="MBPP dataset">
      <data key="d1">CREATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="notes = 'o o| .| o| o| .| .| o o'" target=" musical notes string">
      <data key="d1">PARSED_FROM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix (Gupta et al., 2017)" target="modify programs so that they compile successfully">
      <data key="d1">HAS_OBJECTIVE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Yasunaga &amp; Liang (2020, 2021)" target="PaLM">
      <data key="d1">CITED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gupta et al. (2017)" target="PaLM">
      <data key="d1">CITED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Marie" target="chicken meal">
      <data key="d1">ORDERS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Marie" target="milk">
      <data key="d1">ORDERS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Marie" target="apples">
      <data key="d1">ORDERS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Marie" target="pizza">
      <data key="d1">PAID_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Marie" target="box of pizza">
      <data key="d1">ORDERS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="i" target="1">
      <data key="d1">ITERATED_FROM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="sm" target="0">
      <data key="d1">ASSIGNED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="cost_of_apples_per_apple" target="1.50">
      <data key="d1">EQUALS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="sum_pairwise_products" target="int n)">
      <data key="d1">CALLED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="sum_pairwise_products" target="def sum_pairwise_products (n):">
      <data key="d1">CALLED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="j" target="i">
      <data key="d1">ITERATED_FROM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="cost_of_milk_per_pack" target="3">
      <data key="d1">EQUALS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="packages_of_milk" target="5">
      <data key="d1">EQUALS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="total_paid" target="cost_of_meal">
      <data key="d1">SUBTRACTED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="total_paid" target="cost_of_milk_per_pack">
      <data key="d1">MULTIPLIED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="total_paid" target="cost_of_pizza_per_box">
      <data key="d1">DIVIDED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kulal et al." target="pass@ kmetric">
      <data key="d1">PROPOSED_METRIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="MBPP" target="PaLM-Coder">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TransCoder" target="C++ to Python translation">
      <data key="d1">EXAMPLE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TransCoder" target="PaLM 540B">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="TransCoder" target="PaLM-Coder">
      <data key="d1">COMPARED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="HumanEval" target="PaLM model">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="HumanEval" target="Codex 12B">
      <data key="d1">IS_COMPARABLE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="HumanEval" target="PaLM-Coder">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex" target="OpenAI Davinci Codex API">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex" target="Researchers (Chen et al., 2021)">
      <data key="d1">MEASURED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex" target="LaMDA">
      <data key="d1">SUPERSEDES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex" target="minor stylistic changes">
      <data key="d1">CAPABLE_OF_MAKING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex 12B" target="100B">
      <data key="d1">TRAINING_DATA_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex 12B" target="18B">
      <data key="d1">TRAINING_DATA_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex 12B" target="39B code tokens">
      <data key="d1">REPORTED_TRAINING_DATASET_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Codex 12B" target="PaLM">
      <data key="d1">SHOWS_COMPARABLE_PERFORMANCE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="46.8B">
      <data key="d1">TRAINING_DATA_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="8.7B">
      <data key="d1">FINE_TUNING_DATA_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="39B">
      <data key="d1">PRE_TRAINING_DATA_SIZE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="39B code tokens">
      <data key="d1">USED_PRETRAINING_AND_FINE_TUNING_DATA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="5.8B tokens from GitHub repositories">
      <data key="d1">USED_PRETRAINING_AND_FINE_TUNING_DATA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="Pre-training and fine-tuning data">
      <data key="d1">SHOWS_TOTAL_TOKEN_COUNT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="code">
      <data key="d1">FINE_TUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="6.5B tokens">
      <data key="d1">FINE_TUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="62B tokens">
      <data key="d1">FINE_TUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="8b">
      <data key="d1">SCALE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="64b">
      <data key="d1">SCALE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="535b">
      <data key="d1">SCALE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="DeepFix code repair task">
      <data key="d1">DEMONSTRATES_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="82.1%">
      <data key="d1">REACHED_COMPILE_RATE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="71.7%">
      <data key="d1">COMPARISON_TO_PRIOR_WORK</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="small normalized edit distances">
      <data key="d1">HAS_HIGHEST_SUCCESS_RATE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="Codex">
      <data key="d1">CHANGES_FEWER_CHARACTERS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="changed prompt">
      <data key="d1">RESPONDS_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="code fixes">
      <data key="d1">PREDICTS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="compile rate">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="success rate for at most 5 lines changed">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="new prompts">
      <data key="d1">LESS LIKELY TO COMBINE VARIABLE DECLARATIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="DeepFix dataset">
      <data key="d1">PRODUCES_SUGGESTIONS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder" target="DeepFix">
      <data key="d1">IS_COMPARED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Davinci Codex training data" target="Evaluation datasets">
      <data key="d1">CONTAMINATION_LEVEL_UNKNOWN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ExtraPythonData" target="5.8B tokens from GitHub repositories">
      <data key="d1">INCLUDED_IN_TRAINING_DATA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ExtraPythonData" target="Python code">
      <data key="d1">CONTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="44.8B tokens">
      <data key="d1">USED_PRETRAINING_AND_FINE_TUNING_DATA</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="LaMDA">
      <data key="d1">SUPERSEDES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="HumanEval">
      <data key="d1">IMPROVES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="MBPP">
      <data key="d1">PERFORMS_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="88.4% pass@100">
      <data key="d1">HAS_CHARACTERISTIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="+12% absolute improvement">
      <data key="d1">HAS_CHARACTERISTIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B" target="+5% absolute improvement">
      <data key="d1">HAS_CHARACTERISTIC</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Chen" target="further ﬁnetuning on code">
      <data key="d1">PERFORMED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Davinci" target="code">
      <data key="d1">FINE_TUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 12" target="PaLM-Coder results">
      <data key="d1">SHOWCASES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="6.5B tokens" target="mixture of 60% Python code and 30% code across languages">
      <data key="d1">FINE_TUNED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="observation" target="Kaplan et al.">
      <data key="d1">OBSERVED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="larger models" target="smaller models">
      <data key="d1">MORE_SAMPLE_EFFICIENT_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="transfer" target="other programming languages and natural language data">
      <data key="d1">TRANSFER_FROM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix" target="PaLM-Coder 540B">
      <data key="d1">PERFORMED_BETTER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix" target="PaLM-Coder">
      <data key="d1">COMPARED_WITH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix" target="PaLM-Coder 540B model">
      <data key="d1">SHOWS_PERFORMANCE_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GSM8K-Python" target="PaLM-Coder">
      <data key="d1">PERFORMED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GSM8K-Python dataset" target="PaLM-Coder 540B">
      <data key="d1">EVALUATED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="GSM8K-Python dataset" target="pass@1 score 57.5">
      <data key="d1">HAS_RESULT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix problem" target="Figure 13">
      <data key="d1">EXEMPLIFIED_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B model" target="58.1 pass@1 score">
      <data key="d1">OBTAINS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B model" target="82.1%">
      <data key="d1">REACHES_COMPILE_RATE_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B model" target="prior work (Yasunaga &amp; Liang, 2021)">
      <data key="d1">OUTPERFORMS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B model" target="Figures 13 and 14">
      <data key="d1">USES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM-Coder 540B model" target="%">
      <data key="d1">HAS_HIGHEST_SUCCESS_RATE_ON_EDITS_WITH_SMALL_NORMALIZED_EDIT_DISTANCES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix problems" target="Figures 13 and 14">
      <data key="d1">SHOWED_EXAMPLES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix problems" target="PaLM-Coder 540B model">
      <data key="d1">SHOWS_SUCCESSFUL_PREDICTIONS_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="model" target="fixed C programs">
      <data key="d1">PREDICTS_THE_ENTIRE_FIXED_CODE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="code formatter" target="broken code">
      <data key="d1">APPLIES_FORMATTING_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="broken C programs" target="model">
      <data key="d1">IS USED AS INPUT FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Davinci Codex" target="%">
      <data key="d1">HAS_HIGHEST_SUCCESS_RATE_ON_EDITS_WITH_FEW_LINES_CHANGED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Davinci Codex" target="few lines changed">
      <data key="d1">HAS_HIGHEST_SUCCESS_RATE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="compile rate" target="Table 13">
      <data key="d1">IMPROVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="success rate for at most 5 lines changed" target="Table 13">
      <data key="d1">IMPROVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix dataset" target="ground truth fixes or input-output examples">
      <data key="d1">LACKS_INFORMATION_ABOUT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="DeepFix dataset" target="C programming course">
      <data key="d1">DRAWN_FROM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 13" target="metrics">
      <data key="d1">SHOWS_IMPROVEMENT_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 13" target="normalized edit distance metrics">
      <data key="d1">IMPROVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 13" target="lines changed metrics">
      <data key="d1">IMPROVED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Dataset poisoning attacks" target="Code completion systems">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LMs" target="Dataset poisoning attacks">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LMs" target="buggy code">
      <data key="d1">PRODUCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LevenshteinDistance" target="Normalized Edit Distance">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Lines Changed" target="DeepFix success rates">
      <data key="d1">USED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="prompt" target="buggy code">
      <data key="d1">CONTAIN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="developers" target="suggested code">
      <data key="d1">REVIEW</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="test suite" target="code suggestions">
      <data key="d1">VERIFY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="code completion systems" target="dataset poisoning attacks">
      <data key="d1">VULNERABLE_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="dataset poisoning attacks" target="incorrect generated code">
      <data key="d1">CAUSES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Qi et al." target="program repair literature">
      <data key="d1">PUBLISHED_STUDY_ON</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Pearce et al." target="security evaluation">
      <data key="d1">PUBLISHED_RESEARCH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Allamanis et al." target="readability evaluation">
      <data key="d1">PUBLISHED_RESEARCH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English-German" target="PaLM">
      <data key="d1">TRANSLATED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English-German" target="WMT">
      <data key="d1">USED_FOR_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English-French" target="PaLM">
      <data key="d1">TRANSLATED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English-French" target="WMT">
      <data key="d1">USED_FOR_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English-Romanian" target="PaLM">
      <data key="d1">TRANSLATED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="English-Romanian" target="WMT">
      <data key="d1">USED_FOR_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kazakh" target="PaLM">
      <data key="d1">IS_LOW_RESOURCE_LANGUAGE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Prior SOTA PaLM 540B" target="PaLM 540B">
      <data key="d1">IS_VERSION_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Finetuned SOTA en fr" target="French">
      <data key="d1">IS_MODEL_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="German" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="WMT'19 English-Kazakh" target="PaLM">
      <data key="d1">IS_EVALUATION_SET</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Zero-resource languages" target="French">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Zero-resource languages" target="German">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="FLAN" target="English-centric language pairs">
      <data key="d1">EVALUATED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="FLAN" target="PaLM">
      <data key="d1">BASELINE_IN_0_SHOT_SETTINGS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 14" target="PaLM">
      <data key="d1">COMPARISON_WITH_PALM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="French-German Setting" target="PaLM-540B Performance">
      <data key="d1">IS_EQUAL_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="German-French Language Pair" target="PaLM-540B">
      <data key="d1">HAS_STRONG_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Kazakh-English Language Pair" target="PaLM-540B">
      <data key="d1">HAS_STRONG_PERFORMANCE</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Multilingual translation" target="Training specialists or generalists">
      <data key="d1">SCENARIO_OF</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Large translation models" target="Downstream tasks">
      <data key="d1">CAN_BE_ADAPTED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="PaLM conﬁguration" target="1 billion parameters">
      <data key="d1">LARGER_THAN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Specialists" target="Generalists">
      <data key="d1">CAN_SERVE_AS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Resource-rich scenarios" target="Training specialists or generalists">
      <data key="d1">REQUIRES</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Generalist models" target="Specialized models">
      <data key="d1">CAN_MATCH</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="LaMDA 137B" target="PaLM">
      <data key="d1">EVALUATED_AGAINST</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="mT5" target="SOTA results">
      <data key="d1">FINETUNED_TO_PERFORM</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="mT5" target="Xue et al. (2021b)">
      <data key="d1">PREVIOUS_SOTA_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BART" target="Lewis et al. (2020)">
      <data key="d1">PREVIOUS_SOTA_MODEL</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Czech" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Russian" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Vietnamese" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Spanish" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Turkish" target="GEM benchmark">
      <data key="d1">INCLUDED_IN</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Duˇsek et al." target="PaLM">
      <data key="d1">CITED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="BLEURT-20" target="PaLM">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Novikova et al." target="PaLM">
      <data key="d1">CITED_BY</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ROUGE-2" target="PaLM">
      <data key="d1">USED_FOR</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ROUGE-2" target="PaLM model checkpoint">
      <data key="d1">USED_FOR_MODEL_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ROUGE-2" target="Results">
      <data key="d1">USED_FOR_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="WebNLG 2020" target="PaLM">
      <data key="d1">RELATED_TO</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="training context" target="pretraining">
      <data key="d1">USED_DURING_PRETRAINING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="F-measure of ROUGE-2" target="PaLM">
      <data key="d1">FOCUS_OF_SECTION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="output prompt" target="output">
      <data key="d1">PREPENDED_TO_OUTPUT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ROUGE" target="Appendix H.3">
      <data key="d1">INCLUDED_IN_APPENDIX</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="inputs and targets" target="decoder-only architecture">
      <data key="d1">CONCATENATED_DURING_FINETUNING</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Gehrmann et al." target="ROUGE-2, ROUGE-L (Lin, 2004), BLEURT-20 (Pu et al., 2021)">
      <data key="d1">PROPOSED_METRICS</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="task-speciﬁc prompt" target="input">
      <data key="d1">CONCATENATED_WITH_INPUT</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ROUGE-L" target="PaLM model checkpoint">
      <data key="d1">USED_FOR_MODEL_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="ROUGE-1" target="PaLM model checkpoint">
      <data key="d1">USED_FOR_MODEL_EVALUATION</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="beam-search" target="decoded">
      <data key="d1">USED_FOR_DECODED</data>
      <data key="d2">1.0</data>
    </edge>
    <edge source="Table 16" target="Appendix H.3">
      <data key="d1">PRESENTED_IN</data>
      <data key="d2">1.0</data>
    </edge>
  </graph>
</graphml>
